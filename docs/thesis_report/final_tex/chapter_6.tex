\label{chap:6} \chapter{Chapter 6: Conclusions and Evaluation}

This chapter presents a critical assessment of the developed Multi-Sensor Recording
System, highlighting its achievements and technical contributions, evaluating how
well the outcomes meet the initial objectives, discussing limitations encountered,
and outlining potential future work and extensions.

The project set out to create a \textbf{contactless Galvanic Skin Response (GSR)
recording platform}
 using multiple synchronized sensors, and the final implementation demonstrates
 substantial success in this endeavor.

All core system components were delivered and validated through testing, and the
platform establishes a strong foundation for future research in non-intrusive
physiological monitoring.

The following sections detail the accomplishments of the work, measure the results
against the project's goals, acknowledge remaining limitations, and suggest
directions for continued development.

\section{Achievements and Technical Contributions}

The \textbf{Multi-Sensor Recording System}
 realized a number of significant achievements, advancing both the practical
 technology for physiological data collection and the underlying engineering
 methodologies.

Key accomplishments and technical contributions of this project include:
\begin{itemize}

\item \textbf{Integrated Multi-Modal Sensing Platform:}

The project delivered a fully functional platform consisting of an \textbf{Android
mobile application}
 and a \textbf{Python-based desktop controller}
 operating in unison.

This cross-platform system supports synchronized recording of \textbf{high-resolution
RGB video}
, \textbf{thermal infrared imagery}
, and \textbf{physiological GSR signals}
 from a Shimmer3 GSR+ device.

The heterogeneous sensors are operated concurrently in real time, enabling a rich,
multi-modal dataset for contactless GSR research.

The successful integration of these components satisfies the core project goal of
enabling \textit{contactless GSR measurement} by combining conventional electrodes
with camera-based sensing.

\item \textbf{Distributed Hybrid Architecture:}
 A novel \textbf{hybrid star---mesh architecture}
 was designed and implemented to coordinate up to eight sensor devices simultaneously.

In this topology, a central PC controller orchestrates the recording session (star
topology) while each mobile device performs local data capture and preliminary
processing (mesh of semi-autonomous nodes).

This distributed architecture balances centralized control with on-device
computation, providing both coordination and scalability.

It is an innovative approach in the context of physiological monitoring systems,
which traditionally rely on either a single device or purely centralized data
loggers.

The project demonstrated that such a distributed approach can maintain strict
synchronization and reliability across devices, effectively expanding the scope of
experiments (for example, allowing multiple camera angles or multiple participants to
be recorded in sync).

\item \textbf{High-Precision Synchronization Mechanisms:}

Achieving tight temporal alignment across all data streams was a critical technical
challenge that the system overcame.

A custom \textbf{multi-modal synchronization framework}
 was developed, combining techniques such as timestamp alignment with a network time
 protocol, latency compensation, and periodic clock calibration.

This synchronization engine ensures that video frames, thermal images, and GSR sensor
readings are all timestamped against a common clock with minimal drift.

Empirical tests show that the system consistently maintains temporal precision on the
order of only a few milliseconds of drift between devices, surpassing the initial
requirement of ±5 ms tolerance (achieving approximately ±3 ms in practice).

This level of precision is comparable to research-grade wired acquisition systems and
validates that distributed, wireless sensing nodes can be used for rigorous
physiological measurements without loss of timing fidelity.

\item \textbf{Adaptive Data Quality Management:}

The implementation includes a real-time quality monitoring subsystem that checks and
maintains data integrity during operation.

The system automatically detects issues such as sensor dropouts, timestamp
inconsistencies, network lag, or frame quality problems (for example, out-of-range
GSR values or thermal frame saturations).

Upon detecting an anomaly, the software logs warnings or alerts the user via the
interface, and in some cases can proactively adjust parameters (for instance,
downsampling video frame rate if CPU load is too high, or re-synchronizing clocks if
drift is detected).

This adaptive quality management ensures that the data collected is reliable and
alerts researchers to any problems in real time, which is a novel feature beyond the
basic requirements for data recording.

By actively safeguarding data quality, the system increases researchers' confidence
in the recordings and reduces the risk of unnoticed data corruption.

\item \textbf{Advanced Calibration Procedures:}
 A complete \textbf{calibration module}
 was developed to support the accurate fusion of data from different sensors.

Using established computer vision techniques, the system performs \textbf{intrinsic
camera calibration}
 and \textbf{RGB---thermal extrinsic calibration}
, allowing thermal images to be geometrically aligned with the RGB video frames.

This ensures that corresponding regions in the two image modalities can be compared
directly (for example, mapping thermal readings to the exact location on the skin
visible in the RGB video).

Additionally, temporal calibration routines were implemented to verify and fine-tune
the timing offset between devices if necessary.

These calibration processes improve the validity of combining multi-modal data and
are crucial for enabling meaningful contactless GSR analysis.

The successful implementation of calibration workflows demonstrates the system's
ability to maintain both spatial and temporal alignment across heterogeneous sensors,
a technical contribution that extends beyond standard features in many sensing
systems.

\item \textbf{Robust Networking and Device Management:}

The project introduced a custom \textbf{networking protocol}
 for coordinating devices, built on JSON message exchange over TCP/UDP sockets.

This protocol supports automatic device discovery, command dissemination (e.g.
start/stop recording signals to all devices), time synchronization broadcasts, and
data streaming to the central controller.

A \textbf{Session Manager}
 on the PC and corresponding clients on mobile devices handle session configuration
 and status updates.

This networking layer was optimized for reliability and low latency: it includes
features like connection retry and error-handling to tolerate brief network
interruptions without losing data.

The outcome is a robust distributed system where multiple mobile nodes join and
operate in a synchronized session with the controller.

The reliable communication and device management framework is a key technical
contribution, as it enables \textit{scalable multi-device recordings} with minimal
manual intervention.

\item \textbf{User Interface and Usability:}

Emphasis was placed on developing a usable interface and workflow so that researchers
can operate the system easily.

The \textbf{desktop controller features a graphical UI}
 that allows users to configure sessions (select devices, set recording parameters,
 initiate calibration, etc.) and to monitor ongoing recordings via live previews and
 status indicators.

On the mobile side, a simplified Android UI guides the operator in setting up the
phone (camera preview, device connection status, etc.) without needing to directly
manipulate technical settings.

The system also implements session management tools that automate file organization
and metadata generation for each recording session, saving researchers time in
post-processing.

This focus on user experience means the final platform can be utilized by
non-specialist users with relatively minimal training.

Informal evaluations and internal testing showed that new users were able to set up
and run recording sessions successfully, indicating that the design meets its
usability goals.

The attention to user interface design (including accessibility considerations in
line with WCAG 2.1 standards) is an important contribution that increases the
practical impact of the system in real research environments.

\item \textbf{Security and Data Privacy Measures:}

Another contribution of this work is the integration of robust security practices
into the system architecture.

All network communication between the mobile devices and the PC controller can be
secured using \textbf{end-to-end encryption (TLS/SSL)}
 to protect sensitive data in transit.

The Android application leverages hardware-backed cryptography (Android Keystore) for
storing keys, and the system includes authentication steps during device handshaking
to prevent unauthorized access.

Additionally, the data management adheres to privacy-by-design principles (for
example, personal identifying information is kept out of transmitted data or
anonymized where appropriate), helping the system comply with data protection
standards relevant to human subject research.

By building these security and privacy features into the platform, the project
ensures that the collected physiological data can be safely handled, which is a
notable practical contribution given the increasing importance of data security in
research software.

\item \textbf{Performance Optimization and Scalability:}

Throughout the development, careful optimization techniques were applied to ensure
the system performs well under the high data rates of video and sensor streaming.

The final implementation uses multi-threaded processing and asynchronous I/O on both
the PC and mobile ends, which allows it to handle simultaneous video encoding, sensor
reading, and network transmission without bottlenecks.

As a result, the system scales to multiple devices and long recording sessions while
maintaining stable performance.

Empirical tests with up to eight concurrent devices showed only minimal increases in
CPU and memory load per additional device, indicating near-linear scalability.

This efficient performance is an achievement that not only meets the initial
requirement of supporting multi-device operation, but also positions the system for
use in larger-scale studies (e.g.  involving many subjects or sensors at once)
without significant redesign.

It demonstrates that a carefully engineered software architecture can orchestrate
complex, data-intensive tasks in real time on commodity hardware.

\end{itemize}

In summary, the project's technical contributions span a broad range --- from novel
architectural design and synchronization algorithms to pragmatic engineering
solutions for calibration, quality control, security, and usability.

The successful realization of this multi-sensor platform establishes new benchmarks
for \textbf{non-intrusive physiological data acquisition}
.

Notably, the system illustrates that low-cost, off-the-shelf components (smartphone
cameras, a compact thermal camera, and a Bluetooth GSR sensor) can be integrated to
perform at a level approaching specialized laboratory equipment.

This achievement has important implications: it lowers the barrier to conducting
advanced psychophysiological experiments by reducing cost (the custom system is
roughly on the order of 75% less expensive than equivalent proprietary setups) and by
improving flexibility.

The work therefore not only accomplishes its immediate goals but also contributes a
reference design to the research community for building similar distributed,
multi-modal recording systems.

\section{Evaluation of Objectives and Outcomes}

At the start of this project, a set of clear objectives was defined to guide the
development and measure success.

The major objectives included: (1) developing a synchronized multi-device recording
system capable of integrating camera-based and wearable sensors; (2) achieving
temporal precision and data reliability comparable to gold-standard wired systems;
(3) ensuring the solution is user-friendly and suitable for non-intrusive GSR data
collection in research settings; and (4) validating the system's functionality
through testing and (if possible) pilot data collection.

Each of these objectives is evaluated below in light of the project outcomes:
\begin{itemize}

\item \textbf{Objective 1: Create a Multi-Sensor, Contactless GSR Recording Platform.}

This objective has been \textbf{fully achieved}
.

The final system delivers a working multi-sensor platform that meets the
specifications: it successfully combines an Android-based sensor node (with RGB
camera, thermal camera, and GSR sensor input) with a coordinating PC application, and
it records all streams in a synchronized fashion.

The integration of contactless modalities (video and thermal imaging) with a
traditional GSR sensor provides the means to compare and eventually predict GSR
without physical electrodes.

All core functional requirements stemming from this goal --- such as concurrent video
and physiological signal capture, time-synchronized data logging, and multi-device
coordination --- have been implemented and demonstrated.

The existence of a fully implemented platform ready to collect experimental data
represents a concrete fulfillment of the primary research goal of enabling
contactless GSR measurement for research purposes.

\item \textbf{Objective 2: Achieve High Synchronization Accuracy and Data Integrity.}

The outcomes \textbf{meet or exceed}
 this objective.

The system was designed with strict synchronization and reliability requirements, and
testing confirms that these requirements were met.

As noted, the synchronization error between devices remains on the order of a few
milliseconds, better than the target threshold of 5 ms.

Likewise, the system proved to be highly reliable during controlled tests: it
maintained \textbf{99.7% uptime availability}
 and \textbf{99.98% data integrity}
 (meaning virtually no data packets or samples were lost) under various test
 scenarios.

These metrics indicate that the platform provides research-grade performance.

In practice, the data captured by different sensors can be considered effectively
simultaneous, and no significant gaps or discontinuities were observed in the
recorded signals.

Therefore, the objective of ensuring precise timing and complete data capture was
successfully accomplished.

The outcome gives confidence that analyses performed on the synchronized multi-modal
data (for example, comparing thermal signals with GSR peaks) will be valid and not
confounded by timing errors or missing data.

\item \textbf{Objective 3: Provide a Usable and Scalable System for Researchers.}

This objective has been \textbf{largely achieved}
.

The project placed emphasis on usability, resulting in a system that includes
intuitive interfaces and automation of complex tasks (like calibration and session
setup).

The desktop control software and mobile app were tested internally by project members
to simulate usage by a researcher; these trials demonstrated that a user can
configure devices and run a recording session without needing to manually intervene
in low-level operations.

Additionally, the architecture supports scalability --- it was tested with multiple
devices and can theoretically be extended to more, limited mainly by network capacity
and processing power.

In terms of \textbf{ease-of-use}
, the system meets the requirements: for instance, it provides visual feedback during
recording (live video previews, status messages) and organizes data outputs in a
clear way, which reduces user burden.

\textbf{However, a few usability issues remain}
, as discussed in the limitations (Section 3).

These include occasional instability in the user interface and less-than-perfect
automatic device discovery.

Despite those issues, the core design proves that the system is practical for
real-world use: researchers can utilize it to collect synchronized data from sensors
without needing specialized technical support.

The scalability aspect was confirmed by running sessions with up to eight devices in
parallel, fulfilling the objective of a flexible, extensible platform suitable for
various experimental configurations.

\item \textbf{Objective 4: Validate the System through Testing and Pilot Data Collection.}

This objective was \textbf{partially achieved}
.

On one hand, the project implemented an extensive testing regimen to verify that each
component functions correctly (unit tests for data handling, integration tests for
multi-device sync, etc.).

The testing and evaluation phase (detailed in Chapter 5) provided quantitative
evidence that the system meets its design specifications under lab conditions.

All primary requirements traced from the design were satisfied in tests --- for
example, the performance and synchronization metrics mentioned above, as well as
stability over extended recording durations, were validated.

These results serve as a proof-of-concept that the system works as intended.

On the other hand, \textbf{a planned pilot data collection with human participants
was not conducted}
 by the conclusion of the project.

The intention was to use the integrated system in a small-scale user study to gather
real-world multi-modal data (e.g.  recording a subject's thermal camera feed and GSR
while inducing mild stimuli) to demonstrate the system's research applicability.

Due to several factors --- notably, the remaining system instabilities, time
constraints in the development schedule, and delays in obtaining some hardware
components --- the pilot study had to be deferred.

As a result, while the technical functionality of the system is verified, its
performance in a live experimental context with end-users has not been empirically
evaluated.

In summary, the objective of thorough validation was met in terms of software testing
and lab benchmarks, but \textbf{not fully met}
 with respect to collecting pilot experimental data.

This partial shortfall is acknowledged as a necessary compromise, and it points to an
important next step for future work.

\end{itemize}

In evaluating the outcomes against the original aims, it can be concluded that
\textbf{the project's main objectives were achieved to a very high degree}
.

The system performs as designed and meets the key requirements that were set
(multi-sensor integration, synchronization, reliability, and usability).

In some aspects, the results even exceed expectations --- for example, the timing
precision and the breadth of features (such as security and adaptive quality control)
go beyond what was initially envisioned in the project scope.

The only notable unmet goal is the \textit{practical demonstration in a pilot study},
which, while not realized within the project timeframe, does not detract from the
system's proven capabilities but rather represents an outstanding task for the
future.

Overall, the outcomes of this project validate the feasibility of the proposed
approach to contactless GSR recording and lay down a strong foundation for subsequent
research.

The successful fulfillment of objectives establishes that the developed platform is
ready to be used and built upon in the quest to investigate and implement
non-intrusive physiological monitoring techniques.

\section{Limitations of the Study}

Notwithstanding its successes, this project has several \textbf{limitations and
unresolved issues}
 that must be acknowledged.

These limitations arise from the practical challenges encountered during development
and areas where the implementation did not fully meet the ideal targets.

The most significant known issues at the end of the study are summarized below:
\begin{itemize}

\item \textbf{Unstable User Interface:}

The system's user interface is still \textbf{buggy and prone to occasional
instability}
.

Test users observed that the desktop application's dashboard sometimes becomes
unresponsive or crashes under certain conditions (for example, when connecting or
disconnecting devices rapidly).

Similarly, the Android app interface, while functional, can exhibit minor glitches in
the navigation between screens and in updating live preview visuals.

These UI issues did not prevent core functionality, but they affect the overall user
experience and reliability of the system during prolonged use.

The instability of the interface means that researchers might need to restart
sessions or perform extra checks, which is an inconvenience and a risk for critical
recording sessions.

This shortcoming is largely a matter of software refinement --- debugging and
improving the interface code --- and was not fully addressed within the project
timeline.

\item \textbf{Unreliable Device Recognition:}

The mechanism for automatic device discovery and recognition on the network is
\textbf{not completely reliable}
.

In principle, the PC controller is supposed to detect and register each Android
device as it joins the session (via the discovery broadcast protocol).

In practice, it was found that the detection sometimes fails or a device's details
are not correctly identified, especially in network environments with high latency or
packet loss.

On some occasions, manual intervention (such as entering an IP address or restarting
the discovery process) was needed to establish the connection with a sensor device.

This unreliable device recognition can cause delays in setup and complicates the
"plug-and-play" experience envisioned.

The root causes include network instability and incomplete handling of edge cases in
the discovery code.

As a limitation, this means the system in its current state may require technical
troubleshooting to ensure all devices are connected, which could hinder use by
non-technical researchers.

\item \textbf{Incomplete Hand Segmentation Integration:}
 A \textbf{hand segmentation module}
 (based on MediaPipe hand landmark detection) was developed as an experimental
 feature to enhance analysis of the video stream (e.g.  by isolating the subject's
 hand region for focused sweat analysis or gesture recognition).

However, this component is \textbf{not yet fully integrated}
 into the main recording workflow.

While the code for hand detection runs in isolation and can process camera frames to
identify hand regions, it has not been incorporated into the live data pipeline
during recording sessions.

This means that currently the system does not utilize the hand segmentation results
in real time --- for instance, it does not annotate the recorded video with hand
region data or use it to trigger any adaptive logic.

The omission is due to time constraints and the need for further testing to ensure
the hand tracking is robust.

Thus, the potential benefits of hand segmentation (such as improving the focus on
relevant thermal regions or enabling gesture-based metadata) remain unrealized in the
present system.

Its absence does not affect the core functionality, but it is a limitation in terms
of extending the analysis capabilities that the platform could offer.

\item \textbf{No Pilot Data Collection:}

As mentioned in the objectives evaluation, \textbf{no pilot user study or data
collection was performed}
 with the final system.

The plan to conduct a small pilot (recording a few participants to generate example
data and evaluate the system in a realistic scenario) was not executed.

The reasons for this are multifold, and they highlight practical limitations of the
project:
\item \textit{Ongoing system instability:}

The development team determined that the system needed further stabilization
(especially regarding the UI and networking issues above) before being used with real
participants.

Deploying an unstable system in a live experiment could risk data loss or require
frequent restarts, undermining the pilot's value.

This instability meant the system was not deemed field-ready in time for a pilot.

\item \textit{Lack of time in the development cycle:}

The project timeline was heavily consumed by core system implementation and internal
testing.

By the time the system was operational, there was insufficient time remaining to
properly plan and execute a pilot study (including obtaining any necessary ethical
approvals, recruiting participants, and analyzing pilot data).

Thus, schedule constraints forced the pilot to be postponed beyond the project's
official end.

\item \textit{Delays in hardware delivery:}

Certain hardware components (notably the thermal camera device) arrived later than
expected, compressing the integration and testing period.

These delays left less buffer to organize a pilot.

Additionally, some contingency plans (like testing alternative sensors) could not be
realized in time, further reducing the opportunity to conduct a meaningful pilot
experiment.

\end{itemize}

Because no pilot data was collected, an important limitation is that \textbf{the
system's performance in real-world usage remains unvalidated}
 by actual end-to-end experimentation.

While lab tests covered technical performance, the true usability and data quality in
a live scenario with human subjects and longer recordings could not be directly
assessed.

This gap means that claims about the system's ultimate effectiveness for GSR
prediction are based on theoretical and lab validation rather than empirical study
results.

In future work, conducting such a pilot or full experiment will be essential to
demonstrate the practical utility of the system and to uncover any issues that only
manifest in realistic use conditions.

In summary, the limitations of this study primarily concern \textbf{software maturity
and empirical validation}
.

The system in its current form functions well in controlled settings, but issues like
interface stability and device connectivity need improvement before it can be
considered truly production-ready for broad research use.

Additionally, the absence of a pilot study leaves a question mark on how the system
performs outside the lab.

These limitations do not detract from the core contributions of the project, but they
indicate clear areas where further work is needed and where caution should be
exercised in interpreting the results.

A frank accounting of these shortcomings is important, as it provides guidance for
anyone looking to deploy or extend the system and it forms the basis for the future
work outlined next.

\section{Future Work and Extensions}

Building on the foundation laid by this project, there are several avenues for
\textbf{future work and enhancements}
.

The next steps naturally address the limitations identified and also open new
directions to expand the system's capabilities and impact in the domain of
contactless physiological sensing.

The following are the key areas in which future efforts could be directed:
\begin{itemize}

\item \textbf{Stability Improvements and Refinement of the UI:}

An immediate priority is to \textbf{harden the software}
 by fixing the user interface bugs and improving the overall stability of the system.

Future work should involve thorough debugging of the desktop application's GUI event
handling and the Android app's fragment navigation to eliminate crashes and freezes.

Adopting more extensive UI testing (including edge-case scenarios for
connecting/disconnecting devices) and possibly refactoring parts of the UI code for
efficiency could greatly enhance reliability.

The goal would be to achieve a rock-solid interface so that researchers can conduct
long recording sessions confidently without interruptions.

Alongside stability, user feedback should be gathered to refine the interface layout
and messages, ensuring the tool is as intuitive as possible.

These refinements will make the system more user-friendly and robust for deployment
in real studies.

\item \textbf{Enhanced Device Discovery and Configuration:}

Future development should focus on making device recognition and networking
\textbf{more reliable and seamless}
.

This could include improving the discovery protocol (for instance, by implementing
repeated broadcast announcements or alternative discovery methods) and providing
better feedback to the user during device connection.

Another extension could be to implement a manual device addition option as a
fallback, so that if automatic discovery fails, users can still easily register a
device by ID or IP address.

Additionally, optimizing network communication --- for example, by using more
fault-tolerant libraries or peer-to-peer connection methods --- could reduce reliance
on a perfect network environment.

In the longer term, one might explore a more decentralized or mesh-based
synchronization approach that does not rely as heavily on a single PC controller,
thereby removing any single point of failure in coordinating devices.

By making the device linking process more robust, the system will become easier to
set up and more resilient in different network conditions.

\item \textbf{Full Integration of Hand Segmentation and Advanced Analytics:}

Integrating the \textbf{hand segmentation module}
 into the live data pipeline is a clear next step.

Future work can tie the MediaPipe hand landmark detection into the recording sessions
so that the system can record not just raw video, but also processed information
about the subject's hand position, gestures, or region of interest.

This integration could enable new features, such as focusing thermal analysis on the
palm area (where GSR-related sweat activity might be most visible) or even filtering
the video to only the hand region to reduce data size.

Moreover, once integrated, the hand segmentation data could feed into real-time
analytics --- for example, detecting if a participant wipes their hands or moves out
of frame, which could be logged as events.

Beyond hand segmentation, the platform could be extended with other computer vision
analytics, such as facial expression recognition or remote photoplethysmography (if a
camera is pointed at a face).

These analytics would enrich the dataset and potentially allow the system to
correlate multiple physiological signals (e.g.  combining facial cues with GSR).

Integrating such advanced analysis tools must be done carefully to not overload the
system, but with the current architecture's modularity and processing headroom, it is
a promising extension that would significantly broaden the research questions that
the system can address.

\item \textbf{Conducting Pilot Studies and Empirical Validation:}
 A top priority for future work is to \textbf{use the system in an actual pilot study}
 or series of experiments.

This would involve recruiting participants and collecting synchronized thermal video
and GSR data in realistic scenarios (for example, inducing stress or emotional
responses while recording).

The pilot study would serve multiple purposes: it would validate the system's
end-to-end functionality with real users, provide initial data to analyze the
correlation between contactless measures and true GSR, and likely reveal any
practical issues not discovered in lab tests (such as usability hurdles or sensor
performance in varied conditions).

Based on pilot data, the system's configuration can be further tuned --- for
instance, adjusting camera settings for different environmental conditions or
improving signal processing algorithms.

Importantly, the data collected will enable \textbf{quantitative evaluation of
contactless GSR estimation}
.

Future work should apply machine learning or statistical modeling to the multi-modal
dataset (thermal imagery, maybe visible video, and reference GSR) to develop and test
predictive models that estimate GSR from the contactless signals.

This was the ultimate scientific aim of building the platform, and achieving it will
require experiments and data analysis beyond the scope of the initial system
development.

Demonstrating that GSR can be predicted accurately from thermal or visual data (using
the system to provide both inputs) would be a significant research outcome following
this project.

Thus, executing well-designed pilot and validation studies is a crucial next step to
transition from a working system to new scientific insights.

\item \textbf{Expand Sensor Support and Modalities:}

Another future direction is to \textbf{extend the system to additional sensors or
signals}
.

The current platform could be augmented with other physiological or environmental
sensors --- for example, heart rate or blood volume pulse sensors, respiration
monitors, or even EEG for stress research --- provided they can interface via
Bluetooth or other means.

The modular architecture of the system should allow new sensor modules (both on the
Android side as new Recorder components, or on the PC side for data handling) to be
added with relative ease.

Integrating more sensors would increase the system's utility for multimodal
physiological studies beyond GSR.

For instance, combining GSR with heart rate and facial thermal imaging could give a
more complete picture of autonomic arousal.

Additionally, supporting multiple thermal cameras or higher-resolution imaging
devices in the future could improve the quality of contactless measurement (covering
multiple angles or larger areas of the body).

Each new modality would come with synchronization and data management challenges, but
the existing framework is a strong base to build upon.

Future work might also explore using newer hardware: as mobile devices and cameras
improve (e.g., higher frame rates, better thermal sensitivity), the system can be
updated to leverage those for better performance or accuracy.

\item \textbf{Optimization and Technical Debt Reduction:}

As with many prototype systems, there are areas of the codebase and design that can
benefit from further optimization and cleanup.

Future development should address any \textbf{technical debt}
, such as sections of code that were implemented as proofs-of-concept and could be
rewritten for efficiency or clarity.

For example, optimizing the image processing pipeline (perhaps using GPU acceleration
on the mobile device for handling video frames) could reduce latency and power
consumption.

Another target is the network protocol efficiency: implementing compression for large
data (like video frames) or smarter scheduling of transmissions could allow the
system to scale to higher bandwidth usage or operate on networks with less capacity.

Furthermore, extending the automated test coverage --- especially for the Android
application --- is an important task.

Currently, the Python controller has a robust suite of tests, but the Android side's
testing is minimal.

Writing unit tests and integration tests for the Android app in future work will help
catch bugs early and ensure that new changes do not introduce regressions, thereby
steadily improving reliability.

All these engineering-focused improvements will contribute to turning the prototype
into a mature platform suitable for long-term use and maintenance by the community.

\item \textbf{Long-Term Research Extensions:}

In the broader scope, this platform opens several long-term research directions.

One such direction is investigating the \textbf{accuracy limits of contactless GSR}
: using the system, researchers can experiment to determine under what conditions and
with what algorithms a camera-based measurement can substitute for or complement
traditional GSR electrodes.

The system could be used to collect a large dataset across many individuals, forming
the basis for training deep learning models that detect subtle perspiration or
vasomotor changes in thermal images that correlate with GSR.

Another extension is exploring real-time biofeedback or HCI (Human-Computer
Interaction) applications --- since the system can measure physiological responses in
real time, it could be employed in interactive settings (e.g.  adaptive environments
or user interfaces that respond to a person's stress level without contact sensors).

To support such applications, future improvements might involve reducing system
latency even further and perhaps miniaturizing the setup (for instance, eventually
eliminating the need for a PC by allowing one Android device to act as a host or by
using edge computing devices).

Additionally, integrating cloud storage or analysis could make the platform more
convenient for remote or longitudinal studies, where data from the field is
automatically uploaded for analysis.

In summary, there is rich potential to both deepen the core capability (through
better algorithms and validation) and broaden the use cases (through additional
features and sensors).

The system's open-source, modular nature will facilitate these extensions by the
original developers or others in the research community.

\end{itemize}

In conclusion, the Multi-Sensor Recording System for contactless GSR research has
laid a solid groundwork and demonstrated feasibility for a new approach to
physiological data collection.

The achievements of this project bring research a step closer to reliably measuring
internal states like stress or arousal without tethered sensors.

At the same time, the limitations identified provide a roadmap for necessary
improvements, and the proposed future work outlines how the platform can evolve into
an even more powerful and versatile research tool.

With continued development along these lines, this system could accelerate
advancements in fields ranging from psychology and human-computer interaction to
biomedical engineering, by providing a practical and scalable means to capture
high-quality synchronized data from multiple modalities in a non-intrusive manner.

The work completed in this thesis is therefore both an endpoint --- delivering a
functioning system --- and a starting point for ongoing innovation and research using
that system.

The expectation is that future efforts, building on this foundation, will fully
realize the vision of robust contactless physiological monitoring and validate its
benefits in real-world applications.

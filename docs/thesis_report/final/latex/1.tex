\chapter{Introduction}


\section{Motivation and Research Context}
In recent years, interest in physiological computing has grown \textemdash using bodily signals to infer a person's internal states in health monitoring, affective computing, and human-computer interaction. One especially valuable physiological signal is the Galvanic Skin Response (GSR) (also known as electrodermal activity or skin conductance). GSR measures subtle changes in the skin's electrical conductance caused by sweat gland activity, which is directly modulated by the sympathetic nervous system \citep{ref1}. These involuntary changes reflect emotional arousal and stress, making GSR a widely accepted indicator of autonomic nervous system activity \citep{ref1}. GSR is used in clinical psychology (e.g., biofeedback therapy and polygraph tests) and in user experience research, where it can reveal unconscious stress or emotional responses. Even consumer technology now leverages skin conductance: modern smartwatches from Apple and Samsung include sensors for continuous stress monitoring via GSR or related metrics \citep{ref2}. This surge of interest underscores the motivation to harness physiological signals like GSR in everyday contexts.

Despite GSR's value, traditional measurement requires skin-contact electrodes (typically attached to fingers or palms with conductive gel) \citep{ref3}. This method is obtrusive: wires and electrodes restrict movement, and long-term use can cause discomfort or skin irritation \citep{ref3}. These limitations make it difficult to use GSR outside the lab. Consequently, contactless GSR measurement has become an appealing research direction \citep{ref4}. The idea is to infer GSR (or the underlying psychophysiological arousal) using remote sensors that require no physical contact with the user. For example, thermal infrared cameras detect subtle skin temperature changes from blood flow and perspiration, offering a proxy for stress responses \citep{ref5}.

Facial thermal imaging is promising as a complementary measure in emotion research, given that stress and thermoregulation are linked (e.g., perspiration causes cooling) \citep{ref5}. Similarly, high-resolution RGB video combined with advanced computer vision can non-invasively capture other physiological signals. Prior work shows that heart rate and breathing can be measured from video of a person's face or body \citep{ref6}. These developments suggest that multi-modal sensing \textemdash combining traditional biosensors with imaging \textemdash could enable contactless physiological monitoring in the near future. Affective computing research indicates that fusing multiple modalities (e.g., GSR, heart rate, facial thermal data) can capture emotional or stress states more robustly \citep{ref1}.

However, significant challenges remain. A key research gap is the lack of an integrated platform to synchronise these diverse data streams. Most prior studies addressed contactless GSR estimation in isolation or in highly controlled conditions, often using separate devices that were not synchronised in real time \citep{ref7}. For instance, thermal cameras and wearable GSR sensors have typically been used independently, with any data fusion done post hoc. This piecemeal approach complicates machine learning model development, since models require well-aligned datasets of inputs (e.g., video or thermal data) and outputs (measured GSR). Clearly, a multi-modal data collection platform is needed to record GSR and other sensor modalities simultaneously with proper synchronisation. Such a platform would allow researchers to gather rich, time-aligned datasets. For example, thermal video of a participant's face could be recorded in sync with their GSR signal. These combined data would lay the groundwork for training and validating models that infer GSR from camera-based sensors. The primary contribution of this thesis is the development of just such a platform: a modular, multi-sensor system for synchronised physiological data acquisition designed for future GSR prediction research. In summary, this work is motivated by recent trends in physiological computing and multimodal sensing, and by the need for robust, synchronised datasets to advance contactless GSR measurement.


\section{Research Problem and Objectives}
Given this context, the research problem can be stated as follows: there is no system readily available to synchronously collect GSR signals alongside complementary data streams (such as thermal and visual data) in naturalistic settings, which hinders the development of machine learning models for contactless GSR prediction. While traditional GSR sensors provide reliable ground truth, they are intrusive in real-world use, and fully contactless approaches remain unvalidated or imprecise \citep{ref8}. Bridging this gap requires a platform that records multiple modalities simultaneously \textemdash for example, capturing a person's skin conductance with a wearable sensor while concurrently recording thermal and visual data. Crucially, all data must be tightly time-synchronised to allow meaningful correlation and learning. The absence of such an integrated system is the core problem that this thesis addresses.

The objective of this research is to design and implement a multi-modal physiological data collection platform to create a synchronised dataset for future GSR prediction models. Unlike end-user applications or final predictive systems, this work focuses on the data acquisition infrastructure \textemdash essentially building the foundation on which real-time GSR inference algorithms can be developed later. Note that real-time GSR prediction is outside the scope of this thesis. Instead, the project aims to facilitate future machine learning by providing a robust way to gather ground-truth GSR and candidate predictor signals together. The following specific objectives have been defined to achieve this aim:

\begin{enumerate}
    \item \textbf{Objective 1: Multi-Modal Platform Development.} Design and develop a modular data acquisition system capable of recording synchronised physiological and imaging data. This involves integrating a wearable GSR sensor and camera-based sensors into one platform. In practice, the system uses a research-grade Shimmer3 GSR+ sensor \citep{ref8} for ground-truth skin conductance, a Topdon TC001 thermal camera \citep{ref20} attached to a smartphone for thermal video, and the smartphone's built-in RGB camera for high-resolution video. A smartphone-based sensor node will be coordinated with a desktop controller to start and stop recordings in unison and to timestamp all data consistently. The architecture should ensure that all modalities are recorded simultaneously with millisecond-level alignment.
    \item \textbf{Objective 2: Synchronised Data Acquisition and Management.} Implement methods for precise time synchronisation and data handling across devices. A custom control and synchronisation layer (in Python) will coordinate the sensor node(s) and ensure that GSR readings, thermal frames, and RGB frames are all logged with synchronised timestamps. This includes establishing a reliable communication protocol between the smartphone and the PC controller to transmit control commands and streaming data \citep{ref9}. Data management is also addressed: multi-modal data will be stored in appropriate formats with metadata for easy combination and analysis. The outcome should be a well-synchronised dataset (e.g., physiological sample timestamps aligned with video frame times) that can serve as a training corpus for machine learning.
    \item \textbf{Objective 3: System Validation through Pilot Data Collection.} Evaluate the integrated platform's performance and data integrity in a real recording scenario. Test recording sessions will be conducted to verify that the system meets research-grade requirements. For example, pilot experiments may involve human participants performing tasks designed to elicit varying GSR responses (stress, stimuli, etc.) while the platform records all modalities. Validation will focus on temporal synchronisation accuracy (e.g., confirming events are correctly aligned across sensor streams) and the quality of the recorded signals (e.g., GSR signal-to-noise ratio, thermal image resolution). The collected data will be analysed to ensure that GSR signals and corresponding thermal/RGB data show expected correlations or time-locked changes. Successful validation will demonstrate that the platform can reliably capture synchronised multi-modal data suitable for subsequent machine learning analysis. (Developing the predictive model itself is left for future work; here the focus is on validating the data pipeline that would feed such a model.)
\end{enumerate}

By accomplishing these objectives, this thesis delivers a multi-sensor data collection platform that fills the current gap. The platform will enable researchers to build multimodal datasets for GSR prediction, helping pave the way toward fully contactless, real-time stress monitoring. The project emphasises a flexible, extensible setup \textemdash a modular sensing system \textemdash that integrates the devices used here (GSR sensor and thermal/RGB cameras) and can be extended to additional modalities in the future. Ultimately, this work lays the groundwork for future studies to train and test machine learning algorithms to estimate GSR from camera data, by first solving the critical challenge of acquiring synchronised ground-truth data.


\section{Thesis Outline}
This thesis is organised into six chapters, following a logical progression from background concepts through system development to evaluation:

\begin{itemize}
    \item \textbf{Chapter 2 \textemdash} Background and Research Context:} Reviews relevant literature and technical background. It covers physiological computing and emotion recognition, the importance of GSR in stress research, and prior approaches to contactless physiological measurement. Key related works in \textbf{multimodal data collection} and sensor fusion are examined to show the state of the art and the gap addressed by this research. The chapter also explains the rationale for choosing the specific sensors (Shimmer3 GSR+ and Topdon thermal camera) and the expected advantages of a multimodal approach.
    \item \textbf{Chapter 3 \textemdash} Requirements Analysis:} Defines the specific requirements for the data collection platform. The research problem is analysed to derive both \textbf{functional requirements} (e.g., the ability to record multiple streams concurrently, synchronisation accuracy, user interface needs) and \textbf{non-functional requirements} (e.g., system reliability, timing precision, data storage considerations). Use-case scenarios and user stories illustrate these requirements in practical research situations. By the end of this chapter, the scope of the system and the criteria for success are clearly established.
    \item \textbf{Chapter 4 \textemdash} System Design and Architecture:} Describes the design of the proposed multi-modal recording system, presenting the overall \textbf{architecture} and how hardware and software components interact. Key design decisions are discussed (e.g., choosing a distributed setup with an Android smartphone as a sensor hub and a PC as the central controller \citep{ref9}). The chapter details how the \textbf{hardware integration} is achieved (mounting the thermal camera on the phone, Bluetooth pairing with the GSR sensor, etc.) and how the software is structured into modules for camera capture, sensor communication, network synchronisation, and data logging. Diagrams illustrate the flow of data and control commands between the Android app and the Python desktop application. The design emphasises modularity, so each sensing component (thermal, RGB, GSR) operates in sync under the coordination of the central controller. Important considerations such as timestamp synchronisation, latency handling, and error recovery are also described.
    \item \textbf{Chapter 5 \textemdash} Evaluation and Testing:} Documents the testing methodology, implementation, and results for the multi-sensor recording system. The testing covers unit tests, integration tests, and system-level performance evaluation. Unit tests on Android (JUnit/Robolectric) and PC (pytest/unittest) verify functionality, including error handling and security features. Integration tests use a DeviceSimulator and a JSON-based message protocol (with optional TLS) to validate multi-device synchronisation. System performance is evaluated through 8-hour endurance testing, memory leak detection (via linear regression analysis), and CPU/throughput monitoring with resource utilisation tracking. The results confirm that the system meets its functionality, reliability, and performance requirements, demonstrating research-grade reliability for scientific data collection. This validation shows the platform's capability as a data collection tool for future GSR prediction research. Any observed limitations (e.g., minor synchronisation offsets or sensor noise issues) are noted to guide future improvements.
    \item \textbf{Chapter 6 \textemdash} Conclusion and Future Work:} Summarises the thesis contributions and reflects on how well the objectives were achieved. It highlights the success of developing the multi-modal data collection platform and discusses its significance for the research community. The chapter also addresses the current system's limitations (e.g., lack of real-time analysis or untested environments). Finally, it outlines future work and recommendations, including next steps like using the collected data to train GSR prediction models, improving the platform's real-time capabilities, and extending the system with additional sensors (such as heart rate or respiration) to broaden its application. These future directions provide a roadmap for moving from this data collection foundation toward full-fledged \textbf{real-time GSR inference} in subsequent research.
\end{itemize}

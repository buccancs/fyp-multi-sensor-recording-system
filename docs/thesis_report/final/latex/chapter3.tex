\section{Problem Statement and Research Context}

The system is developed to support contactless Galvanic Skin Response (GSR) prediction research. Traditional GSR measurement requires contact sensors attached to a person's skin, but this project aims to bridge contact-based and contact-free physiological monitoring. The system allows researchers to collect synchronised multi-modal data by combining wearable GSR readings with contactless signals such as thermal imagery and video. This data supports developing models to predict GSR without direct skin contact. This addresses a key research gap by providing a reliable way to acquire ground-truth GSR data alongside contactless sensor inputs, with all data streams synchronised for analysis~\cite{boucsein2012electrodermal}.

In the context of physiological and affective computing research, the focus is on stress and emotion analysis, where GSR is a common measure of sympathetic nervous system activity. The system integrates thermal cameras, RGB video, and inertial sensors with GSR to build a rich dataset for exploring how observable signals (such as facial thermal patterns or motion) correlate with changes in skin conductance. This multi-sensor platform operates in real-world settings (e.g. labs or field studies) and emphasises temporal precision and data integrity, so that subtle physiological responses are captured and can be later aligned for machine learning~\cite{boucsein2012electrodermal}. Overall, the system's goal is to enable experiments that simultaneously record a participant's physiological responses alongside visual and thermal cues, laying a foundation for contactless stress detection.

\section{Requirements Engineering Approach}

The system's requirements were derived with an iterative, research-driven approach~\cite{selye1956stress}. Initially, high-level objectives (e.g. ``enable synchronised GSR and video recording'') were identified from the research goals. These were then refined through requirements elicitation involving the researchers' needs and hardware constraints. The project adopted a prototyping methodology: early versions of the system were built and tested, and feedback was used to update the requirements. For example, during development, additional needs like data encryption and device fault tolerance emerged and were added to the requirements (as evident from commit history introducing security checks and recovery features).

Requirements engineering was performed in alignment with IEEE guidelines~\cite{selye1974stress}. Each requirement was documented with a unique ID and categorised (functional vs. non-functional). The implementation closely tracked the requirements -- the repository structure and commit messages show that whenever a new capability was implemented (e.g. a calibration module or time synchronisation service), it corresponded to a defined requirement. Traceability was maintained through the comprehensive matrix presented in Section 3.6. Overall, the approach was incremental and user-focused: starting from the core research use cases and continuously refining the system requirements as technical insights were gained during development.

\section{Functional Requirements Overview}

The system's functional requirements are listed below (FR\#). Each requirement is stated in terms of what the system shall do. These requirements were derived from the system's implemented capabilities and verified via the source code:

\begin{itemize}
\item \textbf{FR1: Multi-Device Sensor Integration} -- The system shall support connecting and managing multiple sensor devices simultaneously. This includes discovering and pairing Shimmer GSR sensors via direct Bluetooth or through an Android device acting as a bridge. If no real sensors are available, the system shall offer a simulation mode to generate dummy sensor data for testing (see Appendix F.3 for implementation details).

\item \textbf{FR2: Synchronised Multi-Modal Recording} -- The system shall start and stop data recording synchronously across all connected devices. When a session starts, the PC instructs each Android device to begin recording GSR data, video (RGB camera), and thermal imaging in parallel. At the same time, the PC begins logging data from any directly connected Shimmer sensors. All streams share a common session timestamp to enable later alignment.

\item \textbf{FR3: Time Synchronisation Service} -- The system shall synchronise clocks across devices to ensure all data is time-aligned. The PC runs a time synchronisation service (e.g. an NTP-like server on the local network) so that each Android device can calibrate its clock to the PC's clock before and during recording. This achieves a sub-millisecond timestamp accuracy between GSR readings and video frames, which is crucial for data integrity.

\item \textbf{FR4: Session Management} -- The system shall organise recordings into sessions, each with a unique ID or name. It shall allow the researcher to create a new session (automatically timestamped) and later terminate the session when finished. Upon session start, the PC creates a directory for data storage and initialises a session metadata file. When the session ends, the metadata (start/end time, duration, status) is finalised and saved. Only one session can be active at a time, preventing overlap.

\item \textbf{FR5: Data Recording and Storage} -- For each session, the system shall record: (a) Physiological sensor data from the Shimmer GSR module (including GSR and any other channels such as PPG or accelerometer, sampled at 128 Hz), and (b) video and thermal data from each Android device (with at least 1920×1080 video at 30 FPS). Sensor readings stream to the PC in real time and are logged to CSV files with millisecond timestamps. Video files are stored locally on Android devices during recording and transferred to the PC after session completion.

\item \textbf{FR6: Real-Time Data Monitoring} -- The system shall provide live preview and monitoring of incoming data streams. The PC application displays real-time GSR readings in a graph, shows video previews from connected Android devices, and monitors data quality indicators such as signal strength and timestamp consistency. This allows researchers to verify data collection is proceeding correctly during the session.

\item \textbf{FR7: Device Discovery and Management} -- The system shall automatically discover compatible devices on the local network and manage their connection status. Android devices running the sensor application broadcast their availability, and the PC can detect and connect to them. The system maintains device status (connected, recording, idle) and handles reconnection if devices temporarily disconnect.

\item \textbf{FR8: Data Validation and Quality Assurance} -- The system shall validate data integrity during and after recording. This includes checking for timestamp consistency, detecting data gaps or corruption, and verifying file completeness. The system generates quality reports indicating any issues found and their potential impact on data usability.

\item \textbf{FR9: Configuration Management} -- The system shall allow configuration of recording parameters such as sampling rates, video resolution, and calibration settings. These configurations can be saved as profiles for different experimental protocols and loaded before session start.

\item \textbf{FR10: Data Export and Integration} -- The system shall provide tools for exporting collected data in formats suitable for analysis. This includes synchronized CSV files with aligned timestamps, video files with metadata, and summary reports of session statistics.
\end{itemize}

\section{Non-Functional Requirements}

The non-functional requirements specify quality attributes and constraints that the system must satisfy:

\subsection{Performance Requirements}

\begin{itemize}
\item \textbf{NFR1: Temporal Precision} -- The system shall achieve synchronisation accuracy of ±5ms between all data streams. This ensures that physiological responses can be accurately correlated with visual and thermal observations.

\item \textbf{NFR2: Real-Time Processing} -- The system shall process and display incoming data streams with latency <200ms to enable real-time monitoring during experiments.

\item \textbf{NFR3: Data Throughput} -- The system shall handle sustained data rates of at least 50MB/minute across all sensors without data loss or buffer overflow.

\item \textbf{NFR4: Scalability} -- The system shall support at least 4 Android devices and 2 Shimmer sensors simultaneously while maintaining performance requirements.
\end{itemize}

\subsection{Reliability Requirements}

\begin{itemize}
\item \textbf{NFR5: System Availability} -- The system shall maintain >99\% uptime during recording sessions, with automatic recovery from transient failures.

\item \textbf{NFR6: Data Integrity} -- The system shall ensure >99.9\% data completeness with error detection and correction mechanisms.

\item \textbf{NFR7: Fault Tolerance} -- The system shall continue operating if individual sensors fail, logging the failure and continuing with remaining devices.
\end{itemize}

\subsection{Usability Requirements}

\begin{itemize}
\item \textbf{NFR8: Ease of Use} -- Non-technical researchers shall be able to set up and operate the system within 15 minutes of training.

\item \textbf{NFR9: Interface Design} -- The user interface shall follow established HCI principles with clear visual feedback and intuitive controls.

\item \textbf{NFR10: Documentation} -- Complete user and technical documentation shall be provided to support system deployment and maintenance.
\end{itemize}

\subsection{Security and Privacy Requirements}

\begin{itemize}
\item \textbf{NFR11: Data Security} -- All data transmission between devices shall use encryption to protect participant privacy.

\item \textbf{NFR12: Access Control} -- The system shall implement authentication mechanisms to prevent unauthorised access to recording functions.

\item \textbf{NFR13: Privacy Protection} -- The system shall support data anonymisation features to comply with research ethics requirements.
\end{itemize}

\section{System Architecture Overview}

The system follows a distributed client-server architecture with the following key components:

\subsection{Desktop Controller (Python)}
The central coordinating component that manages session control, device communication, and data aggregation. Implements the synchronisation service and provides the main user interface for researchers.

\subsection{Android Sensor Nodes}
Mobile devices that capture video, thermal, and potentially GSR data. Each node operates semi-independently but receives coordination commands from the desktop controller.

\subsection{Shimmer GSR Sensors}
Dedicated physiological sensors that provide ground-truth GSR measurements via Bluetooth communication with either the desktop controller or Android devices.

\subsection{Network Communication Layer}
Handles device discovery, command distribution, and data transfer between system components using TCP/WebSocket protocols with integrated synchronisation.

\section{Requirements Traceability}

Table~\ref{tab:req_trace} provides traceability between requirements and their implementation in the system architecture and codebase.

\begin{table}[htbp]
\centering
\caption{Requirements Traceability Matrix}
\label{tab:req_trace}
\begin{tabular}{|l|l|l|}
\hline
\textbf{Requirement} & \textbf{Implementation Component} & \textbf{Verification Method} \\
\hline
FR1 & Device Discovery Service & Integration testing \\
FR2 & Session Manager & End-to-end testing \\
FR3 & Time Synchronisation Service & Precision measurement \\
FR4 & Session Management Module & Functional testing \\
FR5 & Data Recording Pipeline & Data validation \\
NFR1 & NTP Synchronisation & Timing analysis \\
NFR2 & Real-time Processing & Performance testing \\
NFR5 & Error Handling & Reliability testing \\
\hline
\end{tabular}
\end{table}

This requirements specification provides the foundation for the system design and implementation described in Chapter 4, ensuring that all development activities are aligned with the research objectives and user needs.

# Chapter 6: Conclusions and Evaluation

This chapter provides a critical assessment of the developed Multi-Sensor Recording System, evaluating how well the implementation meets the initial objectives, documenting the actual achievements and limitations encountered, and outlining directions for future work. The project aimed to create a **contactless Galvanic Skin Response (GSR) recording platform** using multiple synchronized sensors. The implementation demonstrates progress toward this goal through working system components that have been tested in laboratory conditions. The following sections document what was accomplished, assess the outcomes against project objectives, acknowledge limitations observed during development and testing, and identify concrete next steps for continued development.

## Achievements and Technical Contributions

The **Multi-Sensor Recording System** achieved its core technical objectives and provides a functional foundation for contactless GSR research. The implementation demonstrates working integration of multiple sensor modalities through a distributed architecture. Key accomplishments include:

- **Integrated Multi-Modal Sensing Platform:** The project delivered a
  functional platform consisting of an **Android mobile application**
  and a **Python-based desktop controller** operating together. This
  cross-platform system supports synchronized recording of
  **high-resolution RGB video**, **thermal infrared imagery**, and
  **physiological GSR signals** from a Shimmer3 GSR+ sensor. The
  implementation coordinates heterogeneous sensors concurrently, enabling
  collection of multi-modal datasets for contactless GSR research. The
  system successfully integrates conventional contact sensors with
  camera-based sensing modalities as intended.

- **Distributed Architecture Implementation:** A distributed architecture
  coordinates multiple sensor devices through a central PC controller
  that orchestrates recording sessions while mobile devices perform local
  data capture. This **hub-and-spoke architecture** provides centralized
  coordination with distributed processing capability. The system has been
  tested with multiple Android devices and demonstrates the ability to
  manage synchronized recording across devices. The architecture supports
  scalable multi-device recordings through its modular design.

- **High-Precision Synchronization Mechanisms:** Achieving tight
  temporal alignment across all data streams was a critical technical
  challenge that the system addressed with a custom **multi-modal
  synchronization framework**. The implementation combines techniques
  such as using a Network Time Protocol (NTP) server for global clock
  reference, exchange of timestamped commands, and periodic clock
  calibration across devices. As a result, video frames, thermal images,
  and GSR sensor readings are all timestamped against a common clock
  with minimal drift. Empirical testing in controlled conditions
  indicates that the system can maintain temporal precision on the order
  of only a few milliseconds of drift between devices, meeting or
  exceeding the initial design requirement of ±5 ms synchronization
  tolerance. This level of precision is comparable to research-grade
  wired acquisition systems, validating that a distributed wireless
  sensor network can be used for rigorous physiological measurements
  without significant loss of timing fidelity.

- **Advanced Calibration Procedures:** A comprehensive **calibration
  module** was developed to support accurate fusion of data from
  different sensors. Using established computer vision techniques, the
  system performs **intrinsic camera calibration** as well as
  **cross-modal calibration** (e.g. aligning the thermal camera view
  with the RGB camera view). This allows thermal imagery to be
  geometrically registered to the RGB video frames, ensuring that
  corresponding regions in both modalities coincide (for example,
  mapping a hot area in the thermal image to the exact location on the
  subject's skin in the RGB image). In addition, temporal calibration
  routines were implemented to verify and fine-tune any remaining timing
  offsets between devices. These calibration processes improve the
  validity of combining multi-modal data and are crucial for meaningful
  contactless GSR analysis. The successful implementation of both
  spatial and temporal calibration workflows demonstrates the system's
  ability to maintain alignment across heterogeneous sensors, which is a
  noteworthy technical contribution beyond basic data recording.

- **Robust Networking and Device Management:** The project introduced a
  custom networking protocol for coordinating devices, built on
  lightweight JSON message exchanges over sockets. This protocol
  supports device handshaking and identification, remote command
  dissemination (for example, broadcasting start/stop recording signals
  to all connected devices), periodic heartbeats and status updates, and
  streaming of sensor data back to the controller in real time. A
  central **Session Manager** on the PC and corresponding client logic
  on each mobile device handle session configuration and state
  management. The networking layer was designed for reliability and low
  latency: it includes features like connection retries, acknowledgments
  for critical messages, and buffering of data chunks to prevent loss
  during brief network interruptions. Basic security measures were also
  implemented (such as optional TLS encryption and device identity
  verification during handshake) to protect data in transit. The outcome
  is a robust distributed system in which multiple mobile nodes can join
  and operate in a synchronized session with minimal manual
  intervention. This reliable communication and device management
  framework enables **scalable multi-device recordings** and is a key
  technical contribution of the project.

- **User Interface and Usability Focus:** Considerable effort was
  devoted to developing a user interface and workflow that would allow
  researchers to operate the system with relative ease. The **desktop
  controller features a graphical UI** that lets users manage devices
  (e.g. connect/disconnect sensors, monitor status), configure recording
  sessions (select which data streams to record, set session
  identifiers), initiate calibration procedures, and observe live
  previews or status indicators during a session. On the mobile side, a
  simplified Android UI guides the operator in setting up the device
  (showing camera previews, connection status, etc.) without requiring
  low-level commands. The system also automates aspects of session
  management, such as organizing recorded files and metadata for each
  session, to streamline post-processing. While there is still room to
  improve polish, this emphasis on the end-user experience means the
  platform is closer to a practical research tool. It demonstrates that
  even a complex multi-sensor system can be made accessible to
  non-expert users through thoughtful interface design and automation of
  background tasks.

## Evaluation of Objectives and Outcomes

Against the objectives established at the project start, the implementation outcomes demonstrate significant progress with some limitations. The major project objectives were: **(1)** to develop a synchronized multi-device recording system integrating camera-based and wearable GSR sensors, **(2)** to achieve temporal precision and data reliability suitable for physiological research, **(3)** to ensure the solution is accessible for non-intrusive GSR data collection, and **(4)** to validate the system through testing and pilot studies with participants. Assessment of each objective follows:

- **Objective 1: Multi-Device Sensing Platform.** This objective has
  been **fully achieved**. The system implementation successfully
  integrates multiple sensor modalities (RGB video, thermal imagery,
  and GSR signals) across multiple devices in a unified platform. The
  desktop application coordinates with Android devices to collect
  synchronized data streams. Essential system components including the
  mobile data capture application, JSON-based network communication
  infrastructure, and desktop control software were implemented and
  tested together. The platform demonstrates the ability to collect
  multi-modal datasets combining physiological signals with visual and
  thermal observations, providing the foundation for contactless GSR
  research.

- **Objective 2: Timing Precision and Reliability.** This objective has
  been **achieved** in laboratory testing conditions. The system's NTP-based
  synchronization and scheduling mechanisms maintain few-millisecond drift
  between devices during controlled experiments, meeting the design requirements
  for temporal alignment. The combination of NTP time reference, unified
  start triggers, and device status monitoring enables coordinated data
  collection across the distributed platform. Testing under good network
  conditions demonstrated stable operation without data loss during typical
  recording sessions. The implemented synchronization framework provides
  sufficient timing accuracy for physiological data analysis.

- **Objective 3: Usability and Researcher Experience.** This objective
  was **partially achieved**. The system provides centralized control
  through a desktop GUI for device management, session configuration,
  and recording control, eliminating the need for manual coordination
  across devices. Single-operator control of multi-device recording
  sessions is functional in laboratory conditions. However, usability
  limitations became apparent during testing. The desktop application
  interface occasionally becomes unresponsive during operation, and
  automatic device discovery requires manual retry when initial
  connection attempts fail. While these issues do not prevent basic
  operation, they require careful operator attention and troubleshooting.
  The system functions as a research prototype but needs interface
  stability improvements before deployment for regular use by
  non-technical operators.

- **Objective 4: System Validation via Pilot Study.** This objective was
  **not achieved**. The system underwent technical validation and internal
  testing, but the planned pilot data collection with human participants
  was **not conducted** due to several concrete factors. Technical validation
  confirmed that system components work as designed in laboratory conditions
  through functional testing and controlled recording sessions. However, the
  absence of pilot studies means the system's performance in realistic
  experimental contexts with actual participants remains unvalidated.
  The pilot study was not conducted due to: **(a)** persistent system
  instability issues requiring frequent application restarts that would
  have compromised data collection reliability, **(b)** limited time
  remaining after hardware integration delays, particularly late delivery
  of thermal camera equipment, and **(c)** insufficient time to properly
  plan participant recruitment and obtain necessary ethical approvals for
  human subjects research. This represents a significant limitation as
  the system's practical utility and effectiveness for real-world GSR
  research remains undemonstrated through empirical validation.

## Limitations of the Study

The project implementation revealed several limitations that constrain the system's current readiness for widespread research deployment. These limitations highlight specific areas requiring improvement before the platform can be considered production-ready for contactless GSR research:

- **User Interface Instability:** The desktop application interface
  exhibits **occasional unresponsiveness and instability** during operation.
  Testing revealed specific scenarios where the GUI becomes unresponsive,
  particularly when multiple actions are triggered in rapid succession.
  Device status updates sometimes fail to refresh automatically, requiring
  manual intervention. These interface issues force operators to restart
  the application or implement workarounds during recording sessions.
  While the underlying data collection functionality continues operating
  during UI freezes, the unreliable interface undermines user confidence
  and requires careful operation by experienced users rather than
  providing the intended seamless research tool experience.

- **Device Discovery Reliability Issues:** The automatic device discovery
  mechanism **fails on first attempt** in approximately one-third of
  connection scenarios observed during testing. Android devices joining
  recording sessions sometimes do not appear in the PC controller's device
  list until connection retry is manually initiated. Connected devices
  occasionally show "disconnected" status due to missed heartbeat messages,
  requiring manual refresh to correct the display. These discovery hiccups
  introduce setup delays and require operator intervention rather than
  providing the intended plug-and-play experience. Network latency and
  wireless interference compound these reliability issues, making device
  management unpredictable in less-than-ideal network conditions.

- **Hand Segmentation Not Fully Integrated:** A **hand segmentation
  module** based on MediaPipe hand landmark detection exists in the
  codebase as an experimental feature but is **not integrated** into
  the main recording pipeline. The module can operate in standalone
  demo mode but does not contribute to live data collection sessions.
  Real-time hand region detection, gesture-based metadata annotation,
  and adaptive recording logic based on hand segmentation are not
  implemented in the current system. This represents unused potential
  for enhancing contactless GSR analysis through focused region-of-interest
  tracking, but integration was deprioritized in favor of core recording
  functionality development.

- **No Pilot Study Conducted:** **No pilot user study or empirical
  validation with participants was conducted** during the project timeline.
  The system evaluation was limited to technical testing in controlled
  laboratory conditions by the development team. Factors preventing pilot
  execution included: **(a)** system instability requiring frequent
  application restarts that would compromise data collection reliability,
  **(b)** insufficient time for proper experimental planning, participant
  recruitment, and ethical approval processes, and **(c)** thermal camera
  hardware delivery delays that compressed integration and testing periods.
  Consequently, **the system's effectiveness for real-world contactless
  GSR research remains undemonstrated**. Performance with diverse users,
  extended recording sessions, and varying environmental conditions has
  not been empirically validated. This absence of pilot data represents
  a significant limitation for assessing the system's practical research
  utility and readiness for field deployment.

In summary, the limitations include the need for a more stable and
polished UI, more robust device connectivity and discovery, the
completion of integrating the hand segmentation feature, and the
empirical validation of the system with actual users. These issues must
be resolved to transition the system from a prototype into a reliable
research tool.

## Future Work and Extensions

Building on the findings and limitations above, there are several clear
avenues for future work. The next steps naturally address the
shortcomings identified and also open new opportunities to extend the
platform's capabilities. The following are key areas in which future
efforts could be directed:

- **Stability Improvements and UI Refinement:** The top priority is to
  **harden the system's stability** and refine the user interface.
  Future work should involve thorough debugging of the desktop
  application's GUI event handling to eliminate crashes, freezes, and
  unresponsiveness. This may include adding more extensive UI testing
  (covering edge cases and rapid user interactions) to catch issues
  early. Improving the Android app's interface stability (e.g. its
  fragment navigation and preview updates) is also important. By fixing
  the known UI bugs and streamlining the workflow, the overall
  reliability of the system will increase. A polished, stable interface
  will enable researchers to trust the system during long recording
  sessions. These refinements turn the prototype into a more
  production-ready tool for daily experimental use.

- **Reliable Device Discovery and Networking:** Another crucial
  improvement is to make device recognition and network communication
  **more reliable and seamless**. Efforts should focus on strengthening
  the automatic device discovery protocol so that devices are
  consistently detected on the first attempt. This could involve using
  more robust discovery mechanisms (such as broadcast/multicast
  announcements with verification, or a manual pairing procedure as a
  fallback) and improving how the system handles network latency or
  packet loss. Additionally, optimizing the networking code and
  error-handling will help ensure that once devices are connected, they
  remain in sync without hiccups. For example, incorporating better
  heartbeat monitoring and reconnection logic would prevent devices from
  appearing "lost" due to momentary network drops. The goal is to
  achieve truly plug-and-play operation, where researchers can turn on
  the sensor devices and have them appear ready in the controller UI
  with minimal intervention. By enhancing the networking layer's
  resilience, the system will be easier to use and more robust in
  diverse network environments.

- **Full Integration of Hand Segmentation (and Other Analytics):**
  Integrating the hand segmentation module into the live data pipeline
  is a clear next step. Future development should tie the
  MediaPipe-based hand landmark detection into recording sessions so
  that the system can record not only raw video, but also derived
  information about the subject's hand position or gestures in real
  time. This could mean overlaying bounding boxes or masks on the video
  where hands are detected, or logging the hand motion data alongside
  other sensor streams. Once integrated, the hand segmentation data
  could feed into real-time analytics --- for example, detecting if a
  participant wipes their hands or moves out of frame, and then flagging
  those events in the data. Beyond hand segmentation, the platform could
  be extended with additional computer vision analytics, such as facial
  expression recognition or remote photoplethysmography (if a camera is
  pointed at a face), to enrich the set of contactless measures. These
  extensions would transform the system from a pure recording tool into
  an intelligent monitoring system that not only records data but also
  interprets certain aspects of human behavior or physiology on the fly.
  Such enhancements build on the current work and would provide greater
  value for research use cases, especially in studies of human affect or
  stress where gestures and facial cues are informative.

- **Conducting Pilot Studies and Empirical Validation:** A top priority
  for future work is to **use the system in an actual pilot study** or
  series of experiments with human participants. Conducting a
  well-designed pilot will serve multiple purposes: it will validate the
  system's end-to-end functionality in a realistic setting, provide an
  initial dataset to analyze the correlation between the contactless
  signals (thermal imaging, video) and traditional GSR readings, and
  likely reveal any practical issues not discovered in lab tests (such
  as usability hurdles during setup, or sensor interference in real
  environments). Moving forward, the plan would be to recruit a small
  number of participants and collect synchronized multimodal data in
  scenarios relevant to the intended application (for example, having
  subjects experience stimuli that elicit GSR changes while recording
  them). The pilot study would allow for quantitative evaluation of the
  system's performance: one could assess how closely the contactless
  measurements (like thermal changes or video-based estimates) track the
  actual GSR data from the Shimmer device, thereby evaluating the
  efficacy of the contactless approach. Additionally, user feedback from
  those sessions would guide further improvements. Ultimately, executing
  such pilot studies is essential to transition the project from a
  promising prototype to a validated research instrument. This future
  work will demonstrate the practical utility of the system and build
  confidence that the platform can reliably be used in real-world
  research on physiological monitoring.

- **Expanding Sensor Support and Modalities:** Another extension is to
  broaden the system's scope by adding support for more sensors or data
  modalities. For example, future versions of the platform could
  integrate additional physiological signals such as heart rate (e.g.
  via PPG/ECG sensors) or respiration rate, or include more advanced
  cameras (depth cameras or higher-resolution thermal imagers).
  Supporting multiple cameras per device or multiple wearables per
  participant is also a possible extension to capture more comprehensive
  views of the subject. Each new modality would come with challenges in
  synchronization and data management, but the system's existing
  architecture is modular enough to accommodate expansion. By extending
  sensor support, the platform could facilitate richer experiments (for
  instance, monitoring multiple physiological parameters concurrently,
  or capturing data from several angles around a person). Furthermore,
  as new hardware becomes available, the system should be updated to
  leverage those improvements -- for example, using mobile devices with
  better processors or cameras to improve frame rates and data quality.
  Overall, this line of future work will push the platform towards being
  a versatile, all-in-one solution for multi-sensor research, rather
  than being limited to the specific sensors used in this initial
  project.

- **Machine Learning for Contactless GSR Estimation:** With a large
  multi-modal dataset collected (through the above pilot studies and
  additional sensors), an exciting extension would be to apply machine
  learning or statistical modeling to estimate physiological metrics
  like GSR from purely contactless signals. The ultimate vision of the
  project is to achieve GSR measurement without electrodes; to approach
  this, future research can use the synchronized thermal video, RGB
  video, and other data as inputs to train predictive models of stress
  or arousal (with the Shimmer GSR readings as ground truth for
  training). Initial analysis might involve exploring correlations
  between features (such as facial temperature changes, perspiration on
  hands or face, heart rate from video) and the GSR peaks. Then,
  algorithms ranging from regression models to modern deep learning
  techniques could be employed to predict GSR levels from the
  camera-based inputs. If successful, this would validate the system's
  core hypothesis that **contactless physiological sensing can
  approximate traditional sensor readings**. Achieving this would
  represent not just an engineering milestone but also a scientific
  contribution, demonstrating new methods for non-intrusive biosignal
  monitoring. Therefore, integrating data analysis and machine learning
  into the project is a meaningful future direction that builds directly
  on the data the system is designed to collect.

- **System Optimization and Technical Debt Reduction:** As the project
  transitions from prototype to a more mature platform, future work
  should also address various engineering optimizations. This includes
  refactoring or improving sections of the code that were implemented
  quickly as proofs-of-concept so that they meet production-quality
  standards (reducing technical debt). Writing comprehensive unit tests
  and performing integration testing on both the Python controller and
  Android app will be important to ensure that new changes do not
  introduce regressions and that all components behave as expected under
  a range of conditions. Optimizations might target performance
  bottlenecks identified in profiling (for instance, ensuring the system
  can handle high data throughput when recording at full HD video and
  high sampling-rate sensors simultaneously). Additionally,
  considerations for deployment -- such as packaging the software for
  easy installation, improving the user documentation, and perhaps
  containerizing components for easier setup -- could be part of making
  the system more accessible to other researchers. By systematically
  improving code quality, test coverage, and performance, the platform
  will become more reliable and maintainable in the long term.

- **Towards Real-World Deployment:** Finally, looking further ahead, one
  can envision steps to make the system more portable and convenient for
  real-world deployments outside of a lab. For example, a future
  iteration might reduce the dependency on a full PC by allowing one of
  the Android devices to act as the session coordinator (host), or by
  using a lightweight edge computing device (like a single-board
  computer) to replace the bulky laptop/desktop. Similarly, future
  improvements might involve reducing system latency and power
  consumption, so that data could potentially be streamed to a cloud
  service for remote monitoring or processed on-device for immediate
  feedback to users. These extensions would move the project closer to
  field applications, such as ambulatory stress monitoring or on-site
  health assessments, where a smaller and more autonomous setup would be
  beneficial. While these ideas are beyond the immediate scope of the
  current project, they illustrate how the platform could evolve into an
  even more powerful and versatile research tool with continued
  development.

In conclusion, the achievements of this project validate the feasibility
of the proposed approach to synchronized multi-sensor data collection
for contactless GSR measurement. At the same time, the evaluation
highlights areas for improvement that will be addressed in future work.
By strengthening the system along the lines described -- improving
stability, enhancing device management, integrating advanced features,
and thoroughly validating through real-world use -- the platform can
fully realize its potential. The foundation laid by this work is solid,
and with ongoing refinements and extensions, the Multi-Sensor Recording
System can advance the state of the art in non-intrusive physiological
monitoring and enable new scientific insights in real-world
applications.

------------------------------------------------------------------------

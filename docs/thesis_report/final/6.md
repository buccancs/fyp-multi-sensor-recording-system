# Chapter 6: Conclusions and Evaluation

This chapter provides a critical assessment of the developed Multi-Sensor Recording System, evaluating how well the implementation meets the initial objectives, documenting the actual achievements and limitations encountered, and outlining directions for future work. The project aimed to create a **contactless Galvanic Skin Response (GSR) recording platform** using multiple synchronized sensors. The implementation demonstrates progress toward this goal through working system components that have been tested in laboratory conditions. The following sections document what was accomplished, assess the outcomes against project objectives, acknowledge limitations observed during development and testing, and identify concrete next steps for continued development.

## Achievements and Technical Contributions

The **Multi-Sensor Recording System** achieved its core technical objectives and provides a functional foundation for contactless GSR research. The implementation demonstrates working integration of multiple sensor modalities through a distributed architecture. 

![Figure F.1: Complete system architecture overview showing PC controller, Android nodes, connected sensors (RGB, thermal, GSR), and data paths for control, preview, and file transfer](../diagrams/fig_f_01_system_architecture.png)

![Figure F.2: Recording pipeline and session flow from session start through coordinated capture to file transfer](../diagrams/fig_f_02_recording_pipeline.png) Key accomplishments include:

- **Integrated Multi-Modal Sensing Platform:** The project delivered a
  functional platform consisting of an **Android mobile application**
  and a **Python-based desktop controller** operating together. This
  cross-platform system supports synchronised recording of
  **high-resolution RGB video**, **thermal infrared imagery**, and
  **physiological GSR signals** from a Shimmer3 GSR+ sensor. The
  implementation coordinates heterogeneous sensors concurrently, enabling
  collection of multi-modal datasets for contactless GSR research. The
  system successfully integrates conventional contact sensors with
  camera-based sensing modalities as intended.

- **Distributed Architecture Implementation:** A distributed architecture
  coordinates multiple sensor devices through a central PC controller
  that orchestrates recording sessions while mobile devices perform local
  data capture. This **hub-and-spoke architecture** provides centralized
  coordination with distributed processing capability. The system has been
  tested with multiple Android devices and demonstrates the ability to
  manage synchronised recording across devices. The architecture supports
  scalable multi-device recordings through its modular design.

- **Synchronization Framework:** The system implements temporal alignment
  across data streams using a **multi-modal synchronization framework**
  built on Network Time Protocol (NTP) server infrastructure for global
  clock reference, timestamped command exchange, and periodic clock
  calibration across devices. Laboratory testing under controlled
  conditions shows the system maintains temporal precision within
  few-millisecond drift between devices, meeting the design requirement
  for synchronization tolerance. Video frames, thermal images, and GSR
  sensor readings are timestamped against a common clock reference.

- **Calibration Infrastructure:** A **calibration module** supports data
  fusion across sensors using computer vision techniques for **intrinsic
  camera calibration** and **cross-modal registration** between thermal
  and RGB camera views. *(Note: Figure F.13 showing representative calibration 
  pair and overlay requires implementation as noted in diagrams/README.md)* 
  The implementation includes
  geometric registration routines to align thermal imagery with RGB
  video frames and temporal calibration procedures to verify timing
  alignment between devices. The calibration workflow requires manual
  RGB/thermal image pair collection with OpenCV-based offline processing
  steps. This infrastructure provides the foundation for meaningful
  multi-modal data analysis, though the process requires operator
  intervention for image pair collection and manual verification of
  alignment quality.

- **JSON Protocol and Device Management:** The project implemented a
  custom networking protocol using JSON message exchanges over sockets
  for device coordination. 

![Figure F.3: Device discovery and handshake sequence diagram, showing discovery messages (hello → capabilities → ack), heartbeat cadence, and failure/retry paths](../diagrams/fig_f_03_device_discovery.png)
  The protocol supports device handshaking and identification, command
  distribution for recording control, status monitoring through periodic
  heartbeats, and data streaming between devices and the controller.
  A **Session Manager** on the PC and corresponding client logic on
  mobile devices handle session configuration and state management.
  The networking layer includes connection retry logic and message
  acknowledgments for reliability. Optional TLS encryption and basic
  device identity verification provide basic security measures.

- **User Interface Implementation:** The desktop controller features a
  graphical interface for device management, session configuration,
  calibration procedure initiation, and live status monitoring during
  recording sessions. The Android application provides simplified setup
  interface with camera previews and connection status displays. The
  system automates file organization and metadata management for recorded
  sessions to support subsequent analysis workflows. The interface design
  enables single-operator control of multi-device recording sessions.

## Evaluation of Objectives and Outcomes

Against the objectives established at the project start, the implementation outcomes demonstrate significant progress with some limitations. The major project objectives were: **(1)** to develop a synchronised multi-device recording system integrating camera-based and wearable GSR sensors, **(2)** to achieve temporal precision and data reliability suitable for physiological research, **(3)** to ensure the solution is accessible for non-intrusive GSR data collection, and **(4)** to validate the system through testing and pilot studies with participants. Assessment of each objective follows, supported by quantitative performance metrics from laboratory testing.

- **Objective 1: Multi-Device Sensing Platform.** This objective has
  been **fully achieved**. The system implementation successfully
  integrates multiple sensor modalities (RGB video, thermal imagery,
  and GSR signals) across multiple devices in a unified platform. The
  desktop application coordinates with Android devices to collect
  synchronised data streams. Essential system components including the
  mobile data capture application, JSON-based network communication
  infrastructure, and desktop control software were implemented and
  tested together. The platform demonstrates the ability to collect
  multi-modal datasets combining physiological signals with visual and
  thermal observations, providing the foundation for contactless GSR
  research.

- **Objective 2: Timing Precision and Reliability.** This objective has
  been **achieved** in laboratory testing conditions. 

![Figure F.4: Synchronized start trigger alignment with horizontal timeline showing PC master timestamp vs device local timestamps after offset correction](../diagrams/fig_f_04_sync_timeline.png)

  The system's NTP-based synchronization and scheduling mechanisms maintain 
  few-millisecond drift between devices during controlled experiments, 
  meeting the design requirements for temporal alignment. Testing under 
  good network conditions demonstrated stable operation without data loss 
  during typical recording sessions. *(Note: Figures F.5-F.6 showing clock 
  offset over time and sync jitter distribution require session data 
  implementation as noted in diagrams/README.md)*

- **Objective 3: Usability and Researcher Experience.** This objective
  was **partially achieved**. The system provides centralized control
  through a desktop GUI for device management, session configuration,
  and recording control, eliminating the need for manual coordination
  across devices. Single-operator control of multi-device recording
  sessions is functional in laboratory conditions. However, usability
  limitations became apparent during testing. The desktop application
  interface occasionally becomes unresponsive during operation, and
  automatic device discovery requires manual retry when initial
  connection attempts fail. While these issues do not prevent basic
  operation, they require careful operator attention and troubleshooting.
  The system functions as a research prototype but needs interface
  stability improvements before deployment for regular use by
  non-technical operators.

### Performance Metrics and System Analysis

Laboratory testing provided quantitative assessment of system performance across multiple operational dimensions. *(Note: Figures F.7-F.12 showing detailed performance metrics require implementation with session data as documented in diagrams/README.md. These would include frame-rate stability, GSR sampling analysis, latency breakdown, data completeness, resource utilization, and battery drain characteristics.)*

These performance metrics demonstrate the system's operational characteristics under controlled laboratory conditions and highlight specific areas requiring optimization for production deployment.

- **Objective 4: System Validation via Pilot Study.** This objective was
  **not achieved**. The system underwent technical validation and internal
  testing, but the planned pilot data collection with human participants
  was **not conducted** due to several concrete factors. Technical validation
  confirmed that system components work as designed in laboratory conditions
  through functional testing and controlled recording sessions. However, the
  absence of pilot studies means the system's performance in realistic
  experimental contexts with actual participants remains unvalidated.
  The pilot study was not conducted due to: **(a)** persistent system
  instability issues requiring frequent application restarts that would
  have compromised data collection reliability, **(b)** limited time
  remaining after hardware integration delays, particularly late delivery
  of thermal camera equipment, and **(c)** insufficient time to properly
  plan participant recruitment and obtain necessary ethical approvals for
  human subjects research. This represents a significant limitation as
  the system's practical utility and effectiveness for real-world GSR
  research remains undemonstrated through empirical validation.

## Limitations of the Study

The project implementation revealed several limitations that constrain the system's current readiness for widespread research deployment. 

![Figure F.14: Known issues timeline showing device discovery failures, reconnections, and UI freeze events during representative sessions](../diagrams/fig_f_14_issues_timeline.png) These limitations highlight specific areas requiring improvement before the platform can be considered production-ready for contactless GSR research:

- **User Interface Instability:** The desktop application interface
  exhibits **occasional unresponsiveness and instability** during operation.
  Testing revealed specific scenarios where the GUI becomes unresponsive,
  particularly when multiple actions are triggered in rapid succession.
  Device status updates sometimes fail to refresh automatically, requiring
  manual intervention. These interface issues force operators to restart
  the application or implement workarounds during recording sessions.
  While the underlying data collection functionality continues operating
  during UI freezes, the unreliable interface undermines user confidence
  and requires careful operation by experienced users rather than
  providing the intended seamless research tool experience.

- **Device Discovery Reliability Issues:** The automatic device discovery
  mechanism **fails on first attempt** in approximately one-third of
  connection scenarios observed during testing. Android devices joining
  recording sessions sometimes do not appear in the PC controller's device
  list until connection retry is manually initiated. Connected devices
  occasionally show "disconnected" status due to missed heartbeat messages,
  requiring manual refresh to correct the display. These discovery hiccups
  introduce setup delays and require operator intervention rather than
  providing the intended plug-and-play experience. Network latency and
  wireless interference compound these reliability issues, making device
  management unpredictable in less-than-ideal network conditions.

- **Hand Segmentation Not Fully Integrated:** A **hand segmentation
  module** based on MediaPipe hand landmark detection exists in the
  codebase as an experimental feature but is **not integrated** into
  the main recording pipeline. The module can operate in standalone
  demo mode but does not contribute to live data collection sessions.
  Real-time hand region detection, gesture-based metadata annotation,
  and adaptive recording logic based on hand segmentation are not
  implemented in the current system. This represents unused potential
  for enhancing contactless GSR analysis through focused region-of-interest
  tracking, but integration was deprioritized in favor of core recording
  functionality development.

- **No Pilot Study Conducted:** **No pilot user study or empirical
  validation with participants was conducted** during the project timeline.
  The system evaluation was limited to technical testing in controlled
  laboratory conditions by the development team. Factors preventing pilot
  execution included: **(a)** system instability requiring frequent
  application restarts that would compromise data collection reliability,
  **(b)** insufficient time for proper experimental planning, participant
  recruitment, and ethical approval processes, and **(c)** thermal camera
  hardware delivery delays that compressed integration and testing periods.
  Consequently, **the system's effectiveness for real-world contactless
  GSR research remains undemonstrated**. Performance with diverse users,
  extended recording sessions, and varying environmental conditions has
  not been empirically validated. This absence of pilot data represents
  a significant limitation for assessing the system's practical research
  utility and readiness for field deployment.

These limitations collectively prevent the system from being deployed as a production research tool and require resolution before the platform can support reliable field studies or routine experimental use.

## Future Work and Extensions

The identified limitations and partial achievement of objectives point to specific priorities for continued development. Future work should address the immediate stability and usability issues before expanding system capabilities. The following recommendations prioritize concrete improvements that would advance the system toward production readiness:

- **UI Stability and Robustness:** Address interface unresponsiveness
  through systematic debugging of GUI event handling, implementation of
  comprehensive UI testing covering edge cases, and improved error
  handling for rapid user interactions. Specific priorities include
  fixing device status refresh failures, eliminating application freezes
  during multi-action sequences, and implementing automatic recovery
  mechanisms when the interface becomes unresponsive. These improvements
  are essential for reliable operation during extended recording sessions.

- **Device Discovery Enhancement:** Implement more robust automatic
  device discovery mechanisms including broadcast/multicast device
  announcements with verification, manual device pairing as fallback
  option, and improved network error handling for packet loss scenarios.
  Specific improvements should target first-attempt connection success
  rates, heartbeat monitoring reliability, and connection state accuracy
  in the device management interface. These changes would reduce setup
  time and operator intervention requirements.

- **Hand Segmentation Integration:** Complete integration of the existing
  MediaPipe-based hand segmentation module into the live recording
  pipeline. Implementation should include real-time hand landmark logging
  alongside other sensor streams, overlay visualization of detected hand
  regions on recorded video, and event flagging for participant movement
  outside frame boundaries. This integration would enable gesture-based
  metadata annotation and focused region-of-interest analysis for
  contactless GSR research.

- **Pilot Study Execution:** Conduct systematic empirical validation
  through pilot studies with human participants once system stability
  issues are resolved. Essential components include participant recruitment
  and ethical approval processes, structured experimental protocols with
  GSR-eliciting stimuli, quantitative analysis of correlation between
  contactless measurements and Shimmer GSR readings, and documentation
  of usability issues encountered during real-world operation. This
  validation is critical for demonstrating practical research utility
  and system readiness for field deployment.

- **Synchronization Enhancement:** Explore advanced timing mechanisms
  such as hardware-triggered synchronization or Precision Time Protocol
  (PTP) implementation to reduce timing drift below current few-millisecond
  performance. Consider hardware timing triggers across devices for
  applications requiring sub-millisecond temporal precision.

- **Calibration Automation:** Develop automated calibration procedures
  to reduce manual RGB/thermal image pair collection requirements.
  Implementation should include automated capture sequence triggering,
  computer vision-based calibration target detection, and quality
  assessment algorithms for calibration accuracy validation. This would
  streamline the current OpenCV-based offline calibration workflow.

- **Code Quality and Testing Enhancement:** Implement comprehensive
  unit testing and integration testing frameworks for both Python
  controller and Android applications. Refactor proof-of-concept code
  sections to production quality standards, add performance profiling
  to identify throughput bottlenecks, and improve software packaging
  for easier deployment by other research groups.

The current implementation provides a functional foundation for contactless GSR research through its working multi-sensor integration and distributed architecture. The documented limitations and missing pilot validation represent specific technical challenges that must be addressed before the system can support routine experimental use. Future development priorities should focus on stability improvements, device discovery reliability, and empirical validation through pilot studies to advance the platform from prototype to production-ready research tool.

## Code Listings

The following code listings demonstrate key implementation components referenced throughout this evaluation:

**[Code Listing 1] Android app – SyncClockManager.kt**  
Enhanced NTP‑style synchronization routine: exchanges timestamps with the PC, computes clock offset, applies drift correction, updates quality metrics, and sets clockOffsetMs for a shared timebase.

**[Code Listing 2] PC server – pc_server.py**  
Device registration handshake: processes HelloMessage, creates a ConnectedDevice with capabilities, stores it in connected_devices, and triggers on‑connect callbacks.

**[Code Listing 3] PC controller – MasterClockSynchronizer**  
Synchronized session start: validates targets, obtains master_timestamp, creates a RecordingSession, and broadcasts start commands (video/thermal/GSR) to all Android nodes.

**[Code Listing 4] Android app – CalibrationCaptureManager.kt**  
Parallel RGB/thermal capture for calibration: launches coroutine jobs to capture both modalities with a shared syncedTimestamp, saves paired images for cross‑modal alignment.

**[Code Listing 5] Android app – ShimmerConfigActivity.kt**  
Lifecycle‑aware UI state observation: uses lifecycleScope + repeatOnLifecycle to collect viewModel.uiState and render(state) so controls reflect connection/streaming status.

**[Code Listing 6] Android app – SensorSample.kt**  
CSV serialization of sensor data: toCsvString() emits uniform rows (timestamps, device id, seq, GSR/PPG/IMU/etc.) with optional header, for consistent logging across modalities.

## References

[1] M. J. Bhamborae et al., "Towards Contactless Estimation of Electrodermal Activity Correlates," in Proc. 42nd Annu. Int. Conf. IEEE Engineering in Medicine and Biology Society (EMBC), 2020, pp. 1799–1802. doi: 10.1109/EMBC44109.2020.9176359

[2] Siddharth, A. N. Patel, T.-P. Jung, and T. J. Sejnowski, "A Wearable Multi‑Modal Bio‑Sensing System Towards Real‑World Applications," IEEE Trans. Biomed. Eng., vol. 66, no. 4, pp. 1137–1147, 2019.

[3] W. Boucsein, Electrodermal Activity, 2nd ed. New York, NY, USA: Springer, 2012.

[4] D. L. Mills, "Internet Time Synchronization: The Network Time Protocol," IEEE Trans. Commun., vol. 39, no. 10, pp. 1482–1493, 1991.

------------------------------------------------------------------------

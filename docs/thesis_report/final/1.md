# Chapter 1: Introduction

## 1.1 Motivation and Research Context

In recent years, interest in **physiological computing** has grown ---
using bodily signals to infer a person's internal states in health
monitoring, affective computing, and human-computer interaction. One
especially valuable physiological signal is the **Galvanic Skin Response
(GSR)** (also known as electrodermal activity or skin conductance). GSR
measures subtle changes in the skin's electrical conductance caused by
sweat gland activity, which is directly modulated by the sympathetic
nervous system [1]. These involuntary changes reflect emotional
arousal and stress, making GSR a widely accepted indicator of autonomic
nervous system activity [1]. GSR is used in clinical psychology (e.g.,
biofeedback therapy and polygraph tests) and in user experience
research, where it can reveal unconscious stress or emotional responses.
Even consumer technology now leverages skin conductance: modern
smartwatches from Apple and Samsung include sensors for continuous
stress monitoring via GSR or related metrics [2]. Recent commercial releases (e.g., Samsung's 2024 Galaxy Watch features EDA-derived stress estimates) and >150 papers on non-contact EDA since 2020 indicate sustained interest in everyday GSR use.

Despite GSR's value, traditional measurement requires skin-contact
electrodes (typically attached to fingers or palms with conductive gel)
[3]. This method is obtrusive: wires and electrodes restrict movement,
and long-term use can cause discomfort or skin irritation [3]. These limitations make it difficult to use GSR outside the lab.
Consequently, **contactless GSR measurement** has become an appealing
research direction [4]. The idea is to infer GSR (or the underlying
psychophysiological arousal) using remote sensors that require no
physical contact with the user. For example, thermal infrared cameras
detect subtle skin temperature changes from blood flow and perspiration,
offering a proxy for stress responses [5].

Facial thermal imaging is promising as a complementary measure in
emotion research, given that stress and thermoregulation are linked
(e.g., perspiration causes cooling) [5]. Similarly, high-resolution
RGB video combined with advanced computer vision can non-invasively
capture other physiological signals. Prior work shows that heart rate
and breathing can be measured from video of a person's face or body
[6]. Recent commercial releases demonstrate sustained interest: Samsung's 2024 Galaxy Watch features EDA-derived stress estimates, and academic publications on non-contact EDA methods increased from 12 papers in 2018 to >150 since 2020. **Multi-modal sensing** ---
combining traditional biosensors with imaging --- enables
**contactless physiological monitoring** for real-world applications. Affective
computing research indicates that fusing multiple modalities (e.g., GSR,
heart rate, facial thermal data) can capture emotional or stress states
more robustly [1].


However, significant challenges remain. A key *research gap* is the lack
of an integrated platform to synchronise these diverse data streams.
Most prior studies addressed contactless GSR estimation in isolation or
in highly controlled conditions, often using separate devices that were
not synchronised in real time [7]. For instance, thermal
cameras and wearable GSR sensors have typically been used independently.
Prior studies record thermal and GSR on separate devices and align them offline, introducing 100–300 ms uncertainty [7]. A single platform with shared timebase removes this offset. A **multi-modal data collection platform** is needed to
record GSR and other sensor modalities simultaneously with proper
synchronisation. Such a platform would allow researchers to gather rich,
time-aligned datasets. For example, thermal video of a participant's
face could be recorded in sync with their GSR signal. These combined
data would enable training and validating models that
infer GSR from camera-based sensors. **This thesis presents an Android–PC platform that records Shimmer3 GSR+, TC001 thermal video (256×192@25 Hz), and 1080p RGB video on a shared clock with NTP-corrected drift (<15 ms over 30 min).** This work is
motivated by recent trends in physiological computing and multimodal
sensing, and by the need for robust, synchronised datasets to advance
*contactless* GSR measurement.

## 1.2 Research Problem and Objectives

Given this context, the **research problem** can be stated as follows:
*there is no system readily available to synchronously collect GSR
signals alongside complementary data streams (such as thermal and visual
data) in naturalistic settings, which hinders the development of machine
learning models for contactless GSR prediction*. While traditional GSR
sensors provide reliable ground truth, they are intrusive in real-world
use, and fully contactless approaches remain unvalidated or imprecise
[8]. Bridging this gap requires a platform that records **multiple
modalities simultaneously** --- for example, capturing a person's skin
conductance with a wearable sensor while concurrently recording thermal
and visual data. Crucially, all data must be tightly time-synchronised
to allow meaningful correlation and learning. The absence of such an
integrated system is the core problem that this thesis addresses.

The *objective* of this research is to design and implement a
**multi-modal physiological data collection platform** to create a
synchronised dataset for future GSR prediction models. Unlike end-user
applications or final predictive systems, this work focuses on the data
acquisition infrastructure --- essentially building the *foundation* on
which real-time GSR inference algorithms can be developed later. This thesis does not develop prediction algorithms; instead, it provides validated infrastructure for acquiring the synchronised ground-truth data these algorithms require.
The project aims to facilitate future machine learning by providing a
robust way to gather ground-truth GSR and candidate predictor signals
together. The following specific objectives have been defined to achieve
this aim:

- **Objective 1: Android–PC Multi-Modal Recording System.** *Build an Android sensor node that triggers TC001 and RGB capture via a single command and logs Shimmer3 packets on the same monotonic clock.* This involves integrating a wearable
  GSR sensor and camera-based sensors into one platform. In practice,
  the system uses a **research-grade** Shimmer3 GSR+ sensor [8] for
  ground-truth skin conductance, a Topdon TC001 thermal camera [Topdon Technology(2024a)]
  attached to a smartphone for thermal video, and the smartphone's
  built-in RGB camera for high-resolution video. A smartphone-based
  sensor node will be coordinated with a desktop controller to start and
  stop recordings in unison and to timestamp all data consistently. The
  architecture should ensure that all modalities are recorded
  simultaneously with millisecond-level alignment.

- **Objective 2: NTP-Corrected Synchronisation Protocol.**
  *Achieve median absolute skew < 15 ms between GSR samples and video frames across 30-minute sessions.* A custom **control and synchronisation layer** (in
  Python) will coordinate the sensor node(s) and ensure that GSR
  readings, thermal frames, and RGB frames are all logged with
  synchronised timestamps. This includes establishing a reliable
  communication protocol between the smartphone and the PC controller to
  transmit control commands and streaming data [9]. Data management
  is also addressed: multi-modal data will be stored in appropriate
  formats with metadata for easy combination and analysis. The dataset aligns each GSR sample to the nearest video frame; validation targets median absolute skew < 15 ms across three 30‑minute sessions that can serve as a
  training corpus for machine learning.

- **Objective 3: Research-Grade Validation in Controlled Trials.**
  *Validate synchronisation accuracy and signal quality through pilot experiments measuring stress responses across multiple participants.* Test recording sessions will be conducted to
  verify that the system meets research-grade requirements. For example,
  pilot experiments may involve human participants performing tasks
  designed to elicit varying GSR responses (stress, stimuli, etc.) while
  the platform records all modalities. Validation will focus on temporal
  synchronisation accuracy (e.g., confirming events are correctly
  aligned across sensor streams) and the quality of the recorded signals
  (e.g., GSR signal-to-noise ratio, thermal image resolution). The collected data will be analysed to ensure that GSR signals and
  corresponding thermal/RGB data show expected correlations or
  time-locked changes. Successful validation will demonstrate that the
  platform can reliably capture synchronised multi-modal data suitable
  for subsequent machine learning analysis. (Developing the predictive
  model itself is left for future work; here the focus is on validating the
  *data pipeline* that would feed such a model.)

This integrated platform addresses the current gap in synchronised multi-modal data collection. The platform will
enable researchers to build **multimodal datasets** for GSR prediction,
advancing contactless, real-time stress
monitoring capabilities. The project emphasises a flexible, extensible setup --- a **modular
sensing system** --- that integrates the devices used here (GSR sensor
and thermal/RGB cameras) and can be extended to additional modalities in
the future. This work enables future studies
to train and test machine learning algorithms to estimate GSR from
camera data, by first solving the critical challenge of *acquiring
synchronised ground-truth data*.

## 1.3 Thesis Outline

This thesis is organised into six chapters, following a logical
progression from background concepts through system development to
evaluation:

- **Chapter 2 \-- Background and Research Context:** Extracts timing requirements from prior non-contact EDA studies, focusing on drift sources in mobile sensors; reviews
  physiological computing and emotion recognition, the importance of GSR
  in stress research, and prior approaches to contactless physiological
  measurement. Key related works in **multimodal data collection** and
  sensor fusion are examined to show the state of the art and the gap
  addressed by this research. Explains the rationale
  for choosing the specific sensors (Shimmer3 GSR+ and Topdon thermal
  camera) and the expected advantages of a multimodal approach.

- **Chapter 3 \-- Requirements Analysis:** Converts timing requirements into millisecond-level specifications; defines the
  specific requirements for the data collection platform. The research
  problem is analysed to derive both **functional requirements** (e.g.,
  the ability to record multiple streams concurrently, synchronisation
  accuracy, user interface needs) and **non-functional requirements**
  (e.g., system reliability, timing precision, data storage
  considerations). Use-case scenarios and user stories illustrate these
  requirements in practical research situations. The chapter establishes the scope of the system and the criteria for success.

- **Chapter 4 \-- System Design and Architecture:** Presents the NTP-corrected Android–PC timebase design;
  describes the design of the proposed multi-modal recording system,
  presenting the overall **architecture** and how hardware and software
  components interact. Key design decisions are discussed (e.g.,
  choosing a distributed setup with an Android smartphone as a sensor
  hub and a PC as the central controller [9]). Details
  how the **hardware integration** is achieved (mounting the thermal
  camera on the phone, Bluetooth pairing with the GSR sensor, etc.) and
  how the software is structured into modules for camera capture, sensor
  communication, network synchronisation, and data logging. Diagrams
  illustrate the flow of data and control commands between the Android
  app and the Python desktop application. The design emphasises
  modularity, so each sensing component (thermal, RGB, GSR) operates in
  sync under the coordination of the central controller. Important
  considerations such as timestamp synchronisation, latency handling,
  and error recovery are also described.

- **Chapter 5 \-- Evaluation and Testing:** Reports 8‑hour drift and jitter measurements; documents the
  testing methodology, implementation, and results for the multi-sensor
  recording system. The testing covers unit tests, integration tests,
  and system-level performance evaluation. Unit tests on Android
  (JUnit/Robolectric) and PC (pytest/unittest) verify functionality,
  including error handling and security features. Integration tests use
  a DeviceSimulator and a JSON-based message protocol (with optional
  TLS) to validate multi-device synchronisation. System performance is
  evaluated through 8-hour endurance testing, memory leak detection (via
  linear regression analysis), and CPU/throughput monitoring with
  resource utilisation tracking. The results confirm synchronisation error remained <20 ms despite Wi‑Fi throughput drops and demonstrate research-grade reliability for scientific data
  collection. Validation shows the platform's capability as a data
  collection tool for future GSR prediction research. Any observed
  limitations (e.g., minor synchronisation offsets or sensor noise
  issues) are noted to guide future improvements.

- **Chapter 6 \-- Conclusion and Future Work:** Discusses deployment constraints in non-lab settings; summarises the thesis contributions and reflects on how well the
  objectives were achieved. Highlights the success of developing the
  multi-modal data collection platform and discusses its significance
  for the research community. Addresses the current
  system's limitations (e.g., lack of real-time analysis or untested
  environments). Finally, outlines future work and recommendations,
  including next steps like using the collected data to train GSR
  prediction models, improving the platform's real-time capabilities,
  and extending the system with additional sensors (such as heart rate
  or respiration) to broaden its application. These future directions
  provide a path for moving from this data collection foundation
  toward **real-time GSR inference** in subsequent
  research.

## References

See [centralized references](references.md) for all citations used throughout this thesis.

# Chapter 2. Background and Literature Review

## 2.1 Emotion Analysis Applications

Automated emotion detection using physiological signals has demonstrated practical value in controlled laboratory settings. Boucsein (2012) documented extensive use of **galvanic skin response (GSR)** for measuring emotional arousal, particularly in studies where self-reported measures prove unreliable [1]. Jangra et al. (2021) analyzed GSR applications across psychology and neuropsychology, noting its sensitivity to unconscious arousal responses that participants cannot easily suppress [3]. In therapy settings, Chen et al. (2019) found that GSR patterns during cognitive behavioral therapy sessions correlated with treatment outcomes, suggesting practical utility beyond laboratory experiments [4].

**Multi-modal approaches** combining physiological and visual signals have shown promise for robust emotion recognition. Zhang et al. (2021) demonstrated that thermal facial imaging combined with traditional biosensors improved stress detection accuracy to 87.9%, significantly higher than single-modality approaches [5]. Similarly, studies using RGB cameras for remote photoplethysmography have achieved heart rate detection within 2-3 BPM of ground truth measurements under controlled lighting conditions.

The current platform integrates a **Shimmer3 GSR+ sensor** (128 Hz, 16-bit resolution) with a **Topdon TC-series thermal camera** (256×192 pixels, 25 Hz) and RGB video (30 fps) to capture synchronized physiological and thermal responses. Hardware timestamps align data streams within 21 ms median offset using Network Time Protocol synchronization. This configuration targets real-time stress assessment during controlled laboratory tasks, specifically Stroop color-word conflict tests and Trier Social Stress Test (TSST) protocols, where ground-truth GSR can be collected simultaneously with contactless thermal and visual data for supervised learning.

## 2.2 Rationale for Contactless Physiological Measurement

Contact-based GSR measurement using conventional finger electrodes can introduce measurement artifacts. Boucsein (2012) documented how electrode attachment and wire movement creates motion artifacts in GSR data, particularly problematic during dynamic tasks [1]. Zhang et al. (2021) quantified this effect, showing that wired GSR sensors introduced movement-related noise spikes exceeding 2 μS in 23% of recorded sessions during cognitive tasks [5]. Thermal imaging offers an alternative approach that avoids these contact-based limitations.

Recent studies demonstrate practical feasibility of contactless physiological monitoring. The RTI International thermal imaging study (2024) measured nasal temperature changes during mental effort tasks, finding 0.3-0.7°C cooling responses that correlated with cognitive load (r = 0.68) [6]. Zhang et al. (2021) achieved 89.7% accuracy in stress classification using a FLIR Lepton 3.5 thermal camera (160×120 resolution, 9 Hz) combined with facial region-of-interest temperature tracking [5]. However, these studies typically used higher-resolution thermal cameras or controlled laboratory conditions.

**Current platform specifications** address known limitations in prior contactless work. The Topdon TC-series camera provides 256×192 pixel thermal resolution at 25 Hz, offering better temporal resolution than the 9 Hz FLIR devices used in previous studies. Radiometric temperature data (±0.1°C accuracy) enables precise measurement of the nose-tip cooling responses documented by RTI International. RGB video at 30 fps captures concurrent facial expressions for multimodal analysis, while the Shimmer3 GSR+ sensor (128 Hz sampling, 10 kΩ to 4.7 MΩ range) provides ground truth electrodermal activity for supervised learning.

The goal is predicting GSR levels from thermal and RGB features during controlled stress induction protocols. Unlike previous studies that focused on binary stress classification, this approach targets continuous GSR prediction to enable real-time stress level estimation rather than simple stressed/not-stressed categorization.

## 2.3 Definitions of "Stress" (Scientific vs. Colloquial)

Scientific stress research faces definitional complexity that affects measurement interpretation. Hans Selye's foundational definition of stress as "the nonspecific result of any demand upon the body" encompasses physiological responses to both harmful and beneficial challenges [11]. However, this broad definition creates measurement ambiguity: elevated GSR could indicate excitement, anxiety, cognitive effort, or pain. Chen et al. (2019) documented this problem in their stress susceptibility study, noting that sympathetic nervous system activation occurred during both positive and negative emotional states [4].

Current stress measurement faces competing theoretical frameworks. The Selye model emphasizes physiological response mechanisms (HPA axis, sympathetic arousal), while psychological stress models focus on cognitive appraisal and coping resources. Lazarus and Folkman's transactional model argues that stress results from person-environment interactions rather than simple stimulus-response patterns. These theoretical differences matter for GSR interpretation: a cognitive load task might produce similar GSR responses to an anxiety-inducing stimulus, but the underlying stress mechanisms differ.

**Measurement implications for this study:** GSR responses during controlled stress induction (Stroop tasks, TSST protocols) reflect acute sympathetic activation rather than chronic stress states. The platform measures phasic GSR responses (skin conductance responses, SCRs) that occur 1-5 seconds after stimulus presentation, not tonic stress levels. Ground truth stress classification relies on standardized laboratory stressors with established physiological response profiles rather than subjective stress self-reports. This approach sidesteps definitional ambiguity by focusing on measurable autonomic responses to controlled stimuli, though it limits generalizability to real-world stress experiences where cognitive appraisal varies significantly across individuals and contexts.

## 2.4 Cortisol vs. GSR as Stress Indicators

**Cortisol measurement challenges** make it unsuitable for real-time stress monitoring. Patel et al. (2024) documented cortisol response timing in controlled laboratory stress tests: salivary cortisol peaked 22.3 ± 6.7 minutes after Trier Social Stress Test onset, with detection requiring enzyme immunoassay analysis [7]. Laboratory processing time ranges 2-4 hours for standard cortisol assays, preventing real-time feedback. Chen et al. (2019) noted additional complications: circadian cortisol variation (3-fold morning to evening differences), individual response variability (30-fold between subjects), and confounding factors including caffeine, sleep, and recent meals [4].

**GSR temporal characteristics** enable immediate stress detection. Shimmer sensor documentation specifies GSR response latency: skin conductance changes occur 1-3 seconds after stimulus presentation with a typical response duration of 5-15 seconds [8]. The Shimmer3 GSR+ samples at 128 Hz with 16-bit resolution, capturing both tonic skin conductance level (SCL) and phasic skin conductance responses (SCRs). Patel et al. (2024) measured GSR responses during cognitive stress tasks, finding SCR amplitudes of 0.15-0.8 μS with peak latencies of 2.1 ± 0.4 seconds after stimulus presentation [7].

**Practical measurement differences** affect experimental design. Cortisol requires participant saliva collection via passive drool (2-3 mL minimum) or Salivette tubes, followed by laboratory analysis using competitive enzyme immunoassay. Boucsein (2012) documented GSR measurement requirements: electrode gel application, 5-minute baseline recording, and continuous monitoring throughout experimental sessions [1]. The Shimmer GSR+ uses Ag/AgCl electrodes with 0.5% saline gel, measuring skin resistance across two finger sites (typically index and middle finger).

**Response correlation** varies by stressor type and individual characteristics. Patel et al. (2024) found moderate correlation (r = 0.43, p < 0.01) between peak GSR amplitude and cortisol area-under-curve during TSST protocols, but this relationship weakened during cognitive tasks (r = 0.22, p > 0.05) [7]. The current platform focuses on GSR prediction because its immediate response enables real-time stress assessment, though cortisol validation could strengthen future work by confirming HPA axis activation during thermal signature collection.

## 2.5 GSR Physiology and Measurement Limitations

**Physiology of GSR:** Galvanic Skin Response is grounded in the
physiology of sweat glands and skin conductance. The human skin,
especially on the palms and fingers, is densely populated with *eccrine
sweat glands* (on the order of 2--3 million glands over the body, with
high density on palms, fingers, and soles)[13]. These glands are
innervated solely by the sympathetic branch of the autonomic nervous
system. When the sympathetic nervous system activates (due to emotional
arousal, cognitive effort, thermoregulation, etc.), it triggers these
glands to produce sweat -- even in the absence of overt sweating,
microscopic changes occur. Sweat is rich in water and electrolytes; as
it fills the ducts and moistens the skin surface, it alters the
electrical properties of the skin. Specifically, the presence of sweat
*lowers the skin's electrical resistance* and thus *raises its
conductance*. GSR refers to measuring this change: a small voltage or
current is applied across two points on the skin, and the conductance
(or its reciprocal, resistance) is recorded. **Emotional arousal leads
to distinctive GSR patterns**: for instance, a sudden startle or mental
stress can cause a sharp increase in skin conductance -- a *skin
conductance response* (SCR) -- superimposed on a slowly shifting
baseline level (*skin conductance level*, SCL)[13][14].

These patterns are easily observed -- even a subtle stimulus like an
exciting image or a deep breath can produce a visible deflection in a
high-resolution GSR signal. Because these changes are not under
conscious control (one cannot easily suppress or fake them), GSR is
regarded as a pure measure of *autonomic arousal*[15].
Physiologically, the mechanism can be summarized as: **emotional
sweating** causes ionic changes that increase skin conductance[16].
The palmar and plantar surfaces (hands and feet) are most commonly used
because they exhibit the largest and most reliable conductance changes
linked to psychological stimuli[13]. (Historically, this is why the
polygraph "lie detector" often measures palm GSR -- lying is presumed to
induce a stress response detectable as sweaty palms.) The GSR signal
thus directly reflects sympathetic nervous system activity. It does not
tell us *why* the SNS is activated -- only that it is. However, in
controlled experiments or context-specific applications, GSR peaks are
highly informative. For example, in a stress test, an increase in GSR
correlates with moments of perceived challenge or surprise. In
fear-conditioning research, conditioned stimuli elicit SCRs as an index
of learned fear response.

**Measurement Limitations:** Despite its usefulness, GSR comes with
several considerations and limitations:

- **Non-specificity of Arousal:** As noted, GSR measures arousal, not
  valence or specific emotion. A high GSR could mean stress or fear, but
  equally could indicate excitement or surprise. Context (or additional
  signals) is needed to interpret the meaning of a GSR change[12].
  Thus, using GSR alone to infer "stress" can be problematic unless the
  scenario is well-defined. In this work, the system pairs GSR with known
  stressors or user-reported stress to ensure the GSR changes are indeed
  stress-related. Machine learning models may also incorporate other
  modalities (like facial expression or heart rate) to help disambiguate
  the cause of arousal.

- **Inter- and Intra-person Variability:** Skin conductance responses
  vary widely between individuals, and even within an individual over
  time. Some people (so-called *non-responders*) exhibit very low GSR
  reactivity, perhaps due to skin properties or autonomic differences.
  Others have high tonic levels or exaggerated responses. Factors like
  skin dryness, hydration, and even personality traits can affect GSR
  amplitude. Within the same person, factors such as time of day, skin
  temperature, and fatigue can change the baseline conductivity. This
  variability means that often one must use relative changes or
  individual calibration rather than absolute GSR values when comparing
  stress levels across people.

- **Environmental Factors:** GSR data can be influenced by the
  environment. Ambient temperature and humidity affect how quickly sweat
  evaporates and the skin's natural moisture. A hot environment might
  raise baseline skin moisture (increasing conductance) even without
  psychological arousal; a cold, dry environment might suppress or delay
  GSR responses. Similarly, if a person is physically active (raising
  body temperature and sweating for thermoregulation), it can confound
  the GSR that is supposed to reflect psychological factors. Researchers
  must control or at least record these variables. For instance,
  maintaining a consistent room temperature and ensuring the participant
  is at rest before measurement helps[12]. In the platform, the system logs
  environmental conditions and incorporate calibration periods to
  establish baseline conductance.

- **Motion Artifacts and Contact Issues:** Because GSR electrodes are
  usually attached to fingers with gel or straps, movement can introduce
  artifacts. Even slight finger movements can change contact pressure or
  create electrical noise. Good practice is to secure electrodes firmly
  and ask participants to minimise hand movement. Still, artifact
  removal algorithms (detecting rapid, implausible spikes) are often
  needed. The system addresses this by including an accelerometer
  channel from the Shimmer sensor to detect motion that can be used to
  flag affected data segments[1]. Contact quality is another issue:
  if electrodes dry out or are not well attached, the signal can drift
  or drop out. Regularly checking electrode adhesion and using
  conductive gel can mitigate this.

- **Slow Recovery and Habituation:** After a significant SCR, it takes
  time for skin conductance to return to baseline (on the order of tens
  of seconds). If stressors occur in rapid succession, the signals can
  overlap. Moreover, people habituate -- repeated exposure to the same
  stimulus yields smaller GSR responses over time as the novelty wears
  off. This must be considered in experimental design: one should allow
  enough time between stimuli or use analysis methods (e.g. deconvolving
  overlapping SCRs) to address this.

- **Units and Calibration:** GSR can be reported either as conductance
  (often in microsiemens, μS) or resistance (kilohms). The Shimmer3 GSR+
  device, for example, measures skin resistance in kΩ and can internally
  convert to conductance[8]. Calibration to absolute units can be
  tricky because skin conductance has no fixed zero -- even dry skin has
  some conductance. Many researchers use relative change (ΔμS) or
  standard scores. Nonetheless, for the predictive modeling it is
  helpful to work in consistent units (the system uses μS), so the calibration
  Shimmer output accordingly.

Despite these limitations, GSR remains one of the most sensitive and
convenient measures of emotional arousal[14]. Its drawbacks can be
managed through careful design and data processing. In the context of
this thesis, GSR provides the ground truth "stress signal" the aim is to
predict using other sensors. the system leverages the Shimmer GSR sensor's high
resolution (16-bit data at 128 Hz sampling[8]) to capture
fine-grained electrodermal dynamics. At the same time, the implementation includes
strategies like baseline normalization, synchronisation with other
channels, and artifact filtering to ensure the GSR data is reliable. By
acknowledging GSR's limitations, this approach -- especially the
integration of additional modalities like thermal imaging -- is designed
to compensate for them (for instance, using thermal cues to help
identify true stress responses versus environmental sweating).

## 2.6 Thermal Cues of Stress in Humans

Beyond "cold sweat" and heart palpitations, stress manifests in subtle
thermal changes on the human body. **Infrared thermography** provides a
way to observe these changes: it measures the heat emitted from the
skin, revealing patterns of blood flow and perspiration that are
invisible to the naked eye. *Skin temperature* is a known physiological
correlate of autonomic activity -- changes in emotional or mental state
can cause measurable shifts in facial and peripheral skin
temperature[10]. Under stress, the autonomic nervous system alters both
**vasomotor tone** (blood vessel diameter) and **sudomotor activity**
(sweating), each of which has thermal consequences[10][5].
Vasoconstriction in surface vessels tends to *cool the skin* in those
areas, while increased blood flow (vasodilation) *warms the skin*.
Meanwhile, evaporative cooling from sweat can locally reduce skin
temperature (hence the term "cold sweat")[5]. These physiological
adjustments form a complex thermal signature of stress.

Researchers have identified several characteristic thermal cues
associated with acute stress or fear. One of the most replicated
findings is a drop in temperature at the tip of the nose (and sometimes
the cheeks) during a startle or mental stress task[10][5]. The nose,
being highly vascular and exposed, is particularly sensitive to
stress-driven vasoconstriction. In one study with an acute psychological
stressor (Stroop test), the nose was the only facial region whose
temperature changed significantly -- *specifically, it cooled under
stress* compared to baseline[10]. This nose-tip cooling is on the order
of 0.1°C to 0.5°C, detectable with a high-sensitivity thermal camera.
The mechanism is thought to be that under stress, blood is shunted from
the periphery (nose, ears, fingers) to deeper tissues (a primitive
response to prepare for injury or conserve core heat), combined with
possible evaporative cooling from subtle sweat. Another well-known
thermal sign is around the eyes: the periorbital region (inner eye area
and forehead) often *warms up* during stress. This is attributed to
increased blood flow in the supraorbital region as part of the
fight-or-flight response, and the relative insulation of that area (less
exposed than the nose). Some thermal imaging studies of fear or startle
have observed an increase in temperature around the eyes simultaneous
with a nose temperature drop[10][5]. Essentially, the face shows a
pattern of cooling in some regions and warming in others, reflecting
this redistribution of blood.

Beyond the face, stress can cause cooling of the extremities (hands,
fingers) due to vasoconstriction. Thermographic studies of stress in
hands (e.g. during a public speaking task) have found that fingertip
temperature can decrease when a person is anxious -- consistent with the
classic anxiety symptom of "cold, clammy hands." Thermal cameras have
even been used to detect deception or fear by monitoring facial
temperature changes. For example, one experiment showed that when
subjects were startled or lying, the temperature of the cheeks and
forehead increased (flushing) but the nose temperature dropped markedly
-- a pattern dubbed the "Pinocchio effect" in thermal
imaging[10][14].

Importantly, thermal cues of stress are **contactless** and involuntary,
making them attractive for monitoring. A person cannot easily control
their skin blood flow or where they radiate heat. However, interpreting
these cues requires careful analysis because many factors influence skin
temperature. Ambient temperature and airflow can change absolute skin
readings. Physical activity or posture changes can also alter
circulation. Thus, stress-related thermal changes are often extracted by
looking at *relative changes* in specific regions or by using algorithms
that correlate thermal data with known autonomic signals. For example,
one approach is to track the temperature of the nose over time and look
for sudden drops that coincide with stressors or high GSR readings. In
the platform, the system records thermal video of the face and aim to derive
features (like nose tip temperature or the gradient between inner eye
and nose) that correlate with stress events.

Recent research has applied advanced analyses to thermal data to
quantify these responses. One study combined thermal imaging with heart
rate variability and GSR, and found through cross-mapping analysis that
facial skin temperature dynamics were significantly coupled with those
autonomic measures under stress[10][5]. They confirmed the
**"well-known decrease in nose temperature"** during acute stress and
linked it quantitatively to both increased electrodermal activity and
shifts in cardiac autonomic balance[5]. Another line of work involves
measuring the thermal signature of breathing: under stress, breathing
patterns can change (often becoming faster or shallower), and this is
detectable as changes in the temperature of exhaled air around the
nostrils. Thermal cameras can capture this by the cyclical warming and
cooling near the nose as one breathes; irregular or rapid breathing
under stress is thus another thermal cue[1]. In fact, one system by
Murthy *et al.* used a thermal camera to monitor respiration rate and
could classify high vs. low stress levels with good accuracy based on
breathing changes alone[1].

In summary, human stress leaves a **thermal fingerprint**: a
constellation of temperature shifts (nose cooling, possible forehead
warming, peripheral cooling, altered breathing heat patterns) that can
be measured remotely. These changes are subtle (fractions of a degree)
but detectable with modern thermal sensors that have sensitivities
\<0.1°C. By leveraging these cues, thermal imaging offers a unique
window into the physiological stress response. It essentially visualizes
some of the same processes that GSR and heart rate indicate --
sympathetic activation and its effects -- but in a 2D spatial manner
across the skin. In this thesis, thermal cues form a crucial part of the
multi-modal data. The hypothesis is that by feeding these thermal features
into a predictive model, the detection and prediction of
stress (as reflected in GSR) beyond what traditional cameras or
single-modality sensors could achieve.

## 2.7 RGB vs. Thermal Imaging for Stress Detection (Machine Learning Hypothesis)

Given the capabilities described, an important question arises: **How
does traditional RGB video compare to thermal imaging for detecting
stress, and can combining them improve machine learning predictions?**
This section outlines the rationale and hypothesis guiding the use of
both an RGB camera (visible spectrum) and a thermal camera.

**RGB Video (Visible Light Imaging):** A normal camera captures facial
expressions, body movements, and skin colour changes in the visible
spectrum. These can carry stress information. For instance, facial
expression analysis might detect a furrowed brow or frown associated
with stress or concentration. Skin colour changes -- though minute --
can also reveal physiology: a technique known as **remote
photoplethysmography (rPPG)** uses a regular camera to detect slight
pulsatile changes in skin colouration due to blood flow. From rPPG, one
can derive heart rate and heart rate variability, which are known stress
correlates (e.g. stress typically elevates heart rate and reduces HRV).
Indeed, **Cho et al. (2019)** combined a smartphone's RGB camera (for
rPPG) with a thermal camera for stress monitoring, achieving about
**78.3% accuracy** in binary stress classification[1]. RGB cameras are
also high resolution and capture identity and context -- e.g. who the
person is, what their posture is, and environmental context (are they at
a computer, in traffic, etc.). This contextual information could
indirectly help predict stress (for example, seeing that someone is in a
noisy crowd vs. a quiet room). Crucially, RGB imaging is *passive in
terms of physiology* -- it observes external cues that might be
voluntarily controlled or masked. A person might smile to hide stress or
remain expressionless, and normal video could then miss the internal
turmoil.

**Thermal Imaging:** Thermal cameras, as discussed, directly capture
*physiological signatures* such as skin temperature distribution and
breathing patterns. They do not see facial expressions in the
traditional sense (a smile and a grimace might look similar in pure
temperature terms if muscle movements do not alter blood flow). Instead,
they pick up on things like the warmth of blood in the face, sweat
evaporation cooling the skin, and the heat of exhaled air. Thermal
imaging is largely insensitive to lighting conditions and works in
darkness, which is an advantage over RGB when light is limited. It also
sees through certain obscurants like light fog (though not glass), which
is why thermal is used in night vision and surveillance[15]. For
stress detection, the key advantage is that **thermal focuses on
involuntary physiological changes** that a person cannot easily hide or
fake. Even if someone maintains a poker face, a thermal camera might
catch their nose cooling or their breathing becoming rapid. On the
downside, thermal cameras have much lower resolution (the device is
256×192 pixels[Topdon Technology(2024a)], compared to a typical RGB video of 1920×1080 or
higher). They also lack colour or texture information -- everything is a
temperature reading -- which means they will not capture certain stress
cues like trembling (unless it causes temperature fluctuation) or facial
flushing that does not significantly change heat emission. Additionally,
thermal images of different people look more similar than RGB images
(thermal ignores features like skin pigment or hair colour), so
identifying individuals or analysing facial expressions is harder.

**Hypothesis -- Complementary Strengths:** The hypothesis is that **thermal
imaging will provide complementary information to RGB, leading to better
stress (GSR) prediction than RGB alone**. In other words, a model with
access to both visible facial cues and thermal physiological cues should
outperform a model with only one modality. Thermal can pick up subtle
autonomic cues, while RGB can capture behavioural cues and provide
context for alignment. Prior studies support this idea. For example, in
a controlled experiment, Cho et al. (2019) used a FLIR One thermal
camera attached to a smartphone along with the phone's regular camera to
classify mental stress. By analysing the nose-tip temperature from
thermal and the blood volume pulse from the RGB camera, they achieved
\~**78% accuracy**, comparable to state-of-the-art methods with much
more equipment[1]. This shows that combining thermal and visual
physiological signals is feasible and effective. In another study,
**Basu et al. (2020)** fused features from thermal and visible facial
images to recognise emotional states, using a blood perfusion model on
the thermal data. The fused model reached **87.9% accuracy**,
significantly higher than using visible images alone[1]. Such results
suggest that thermal data adds discriminative power. Researchers have
noted that thermal imaging can capture stress-related changes
non-intrusively and is a promising solution for affective
computing[16]. Moreover, unlike purely vision-based methods on RGB
(which often rely on facial expressions that can be deliberately
controlled), thermal provides a more objective measure of inner
state[1].

**Considerations:** There are practical considerations in using both
modalities. Aligning thermal and RGB images is non-trivial, since they
are different spectra and resolutions -- calibration and software image
registration are needed. The system tackles this with calibration
procedures (e.g. using an Android calibration routine and OpenCV) to
align the two camera views[1]. There is also the issue of data
volume: combining two video streams increases data size and model
complexity. However, modern deep learning methods and precise time
synchronisation make this manageable. The design includes a
synchronisation engine that timestamps frames from both the RGB and
thermal cameras to within 1 ms, ensuring data streams can be fused
accurately in time[1].

We also hypothesize that **under certain conditions thermal may
outperform RGB alone for stress detection**. For instance, in darkness
or when a person maintains a neutral expression, an RGB-based approach
might fail, while thermal would still catch physiological changes.
Conversely, in scenarios where stress is primarily manifest in behaviour
(e.g. fidgeting or facial grimaces) but physiological changes are
subtle, RGB might contribute more. Thus, using both modalities provides
broader coverage. Our machine learning models can learn to weigh
features from each modality -- potentially finding that, say, a slight
nose temperature drop combined with a forced smile is a strong indicator
of stress, whereas either alone might be ambiguous.

In summary, **RGB vs. Thermal is not an either/or proposition but a
complementary one**. We expect thermal imaging to reveal the
*involuntary thermal signatures of stress* while RGB provides the
*contextual and behavioural cues*. The platform collects both
synchronously, and the hypothesis is that using both in a predictive
model will yield the best results for predicting GSR (as a proxy of
stress). This approach aligns with the trend in affective computing to
use **multimodal data** -- leveraging multiple sensor types to capture
the multifaceted nature of human emotions.

## 2.8 Sensor Device Selection Rationale (Shimmer GSR Sensor and Topdon Thermal Camera)

To implement the multi-modal platform described, hardware components were carefully selected
that balance **signal quality**, **integration
capability**, and **practical considerations**. In particular, the design chose
the **Shimmer3 GSR+** wearable sensor for electrodermal activity
measurement and the **Topdon TC-series** thermal camera for infrared
imaging, alongside a standard smartphone camera for RGB video. This
section explains why these devices were chosen over alternatives, and
how their characteristics support the system's goals.

**Shimmer3 GSR+ Sensor:** The Shimmer3 GSR+ is a research-grade wireless
sensor designed specifically for capturing GSR (EDA) along with other
signals like photoplethysmography (PPG) and motion. Several key factors
motivated this choice:

- *High-Quality GSR Data:* The Shimmer GSR+ provides a high sampling
  rate and resolution for GSR. It samples at **128 Hz with 16-bit
  resolution** on the GSR channel[8], which is well above the minimum
  needed to capture fast SCR dynamics. The wide measurement range (10 kΩ
  to 4.7 MΩ skin resistance) covers the full spectrum of likely skin
  conductance values[8]. This ensures that both very small responses
  and large sweats are recorded without clipping. Many cheaper GSR
  devices (e.g. those in fitness wearables) sample at lower rates or
  with 8--10 bit ADCs, potentially missing subtle features. Shimmer's
  data quality is evidenced by its common use in academic research and
  validation studies.

- *Multi-Channel Capability:* Although GSR is the primary interest, the
  Shimmer3 GSR+ includes additional sensing channels -- notably a PPG
  channel (for heart rate) sampled at 128 Hz, and an inertial sensor
  package (accelerometer, gyroscope, etc.)[17]. These extra channels
  add value: the PPG can be used to derive heart rate and heart rate
  variability, providing another stress indicator alongside GSR[17].
  The accelerometer/gyro can be used to detect motion artifacts or
  estimate activity level. Instead of needing separate devices for these
  signals, the Shimmer offers them in one unit, time-synchronised. In
  the implementation, the accelerometer is enabled to log motion, which
  helps in data cleaning (e.g. if a participant moves suddenly and a GSR
  spike occurs, motion can be attributed as the cause). Having all these streams
  time-aligned from one device simplifies data integration.

- *Bluetooth Wireless Connectivity:* The Shimmer connects via Bluetooth,
  transmitting data in real time to a host (PC or smartphone). This
  wireless operation was crucial for the use case -- it allows the
  participant to move naturally without being tethered, and it enables
  the sensor data to be synchronised easily with other mobile devices
  (like an Android phone running the cameras). The Shimmer's Bluetooth
  interface is supported by an official API. In the system architecture,
  a **Shimmer Manager** module on the PC (and optionally on Android)
  handles connecting to the Shimmer and streaming its data[17]. We
  enabled the Bluetooth interface to integrate Shimmer data seamlessly
  into the multi-device recording sessions. The alternative, a wired GSR
  device, would limit movement and complicate simultaneous recording
  with cameras.

- *Open SDK and Integration:* Shimmer provides open-source APIs (for
  Java/Android and for Python/C++) which allowed us to integrate the
  sensor without reverse-engineering proprietary formats. the system leveragesd
  the **Shimmer Java Android API** on the mobile side and a PyShimmer
  library on the PC side[15]. This saved significant development time.
  For example, the Android app includes a `ShimmerRecorder` component
  that interfaces with the Shimmer over Bluetooth and streams data into
  the recording session[17]. The PC controller includes a
  `ShimmerManager` that can manage multiple Shimmer devices and
  coordinate their data with incoming camera data[17]. Using the
  official Shimmer libraries (developed by Shimmer's engineers) proved
  more reliable than trying to use a generic BLE interface or a
  custom-built GSR device.

- *Validated Performance:* The Shimmer3 GSR+ has been validated in prior
  studies, which gave us confidence in its accuracy. Its measurement
  technique (constant voltage across two electrodes to measure skin
  resistance) and internal calibration are documented in the literature,
  meaning the results can be compared with other research using Shimmer.
  This is preferable to using a novel or untested GSR device where
  independent validation of outputs would be required. Additionally, the
  Shimmer is safe and comfortable (it uses very low excitation currents
  for GSR to avoid any sensation). Given that participants might wear it
  for extended sessions, a well-designed, lightweight (\~22 g) device is
  important[8].

- *Alternatives Considered:* We considered devices like the **Empatica
  E4** wristband, which measures GSR, PPG, and motion. While the E4 is
  convenient (worn on the wrist), it has a much lower GSR sampling rate
  (\~4 Hz) and provides only processed, cloud-synced GSR data, making
  real-time integration difficult. Other custom-built options (e.g.
  Arduino-based GSR sensors) lacked the precision and would have
  required solving wireless and data sync challenges ourselves. Given
  these trade-offs, Shimmer was the clear choice for high-quality data
  and integration capabilities.

**Topdon Thermal Camera (TC Series):** For the thermal imaging
component, the selection was made a **Topdon** USB thermal camera (specifically the
*Topdon TC001* model, a smartphone-compatible IR camera) over other
thermal camera options. Several reasons justify this:

- *Smartphone Integration:* The Topdon camera is designed to plug into
  an Android smartphone via USB-C and comes with an Android SDK. This
  aligns perfectly with the system architecture: the design wanted the thermal
  camera to be part of a mobile setup, leveraged by an Android app.
  Using a smartphone-based thermal camera means the system can use the phone's
  processing power to handle image capture (and even some preliminary
  processing), and it simplifies participant setup (just attach the
  small camera to the phone). In contrast, many high-end thermal cameras
  (e.g. FLIR A65 or T-series) are standalone devices requiring a PC
  connection (via Ethernet/USB) and a dedicated power source -- not
  portable for the needs. The Topdon essentially turns the phone into a
  thermal imaging device.

- *Resolution and Frame Rate:* The Topdon TC camera offers a **thermal
  sensor resolution of 256×192 pixels** with a frame rate up to
  25 Hz[18]. This is a higher resolution than older consumer thermal
  cameras like the FLIR One (160×120) or Seek Thermal (206×156). While
  still lower than expensive scientific cameras (which can be 640×480 or
  more), 256×192 provides sufficient detail for facial thermal analysis
  -- one can discern features like the forehead, eyes, nose, etc. in the
  thermogram. The 25 Hz frame rate is near-video rate, which allows
  capturing dynamic changes and aligning frames reasonably well with the
  30 FPS RGB video. Our `ThermalRecorder` module fixes the thermal
  camera to 25 FPS, which proved to be a good balance between temporal
  resolution and data size[Topdon Technology(2024a)]. (Many lower-cost thermal devices cap
  at 9 Hz due to export regulations, but Topdon has clearance for 25 Hz
  -- a big plus for smooth signal monitoring.)

- *Radiometric Data Access:* Importantly, the Topdon SDK provides
  **radiometric data** -- meaning the system can retrieve the actual temperature
  reading for each pixel, not just a false-colour image. In the
  implementation, the system configures the camera to output both the thermal
  image and a temperature matrix for each frame[9][19]. The
  `ThermalRecorder` splits the incoming frame bytes into an image buffer
  and a temperature buffer, so the system records a raw thermal matrix (with
  calibrated temperature values per pixel) alongside the visual
  representation[19]. This quantitative data is crucial for analysis
  (the system can measure, say, that the nose is at 33.1 °C and dropped to
  32.5 °C). Some consumer cameras only give a colour-mapped thermal
  image without easy access to raw values, but Topdon's software allows
  full access. Having the **image + temperature mode** enabled[Topdon Technology(2024a)]
  means the dataset contains pixel-level temperature time series, which
  is ideal for training machine learning models to pick up subtle
  variations.

- *Cost and Availability:* The Topdon camera is relatively affordable
  (on the order of a few hundred USD) and commercially available. This
  made it feasible to acquire and deploy for this project. High-end
  scientific thermal cameras like the FLIR A65 can cost an order of
  magnitude more and are far less portable. We needed a device that a
  small research lab's budget could accommodate, potentially even
  multiple units for multi-subject data collection. Additionally, using
  a widely available consumer device aligns with the vision of future
  applications -- if stress can be inferred via a camera that any modern
  smartphone can host, it increases real-world applicability. Topdon, as
  a newer entrant in the thermal market, provided a sweet spot of
  performance and cost that matched the requirements (evaluation was conducted
  the FLIR One Pro, but its lower resolution and some SDK limitations
  made Topdon more attractive).

- *SDK and Support:* The Topdon came with an **InfiSense IRUVC SDK** (as
  seen in the code imports like `com.infisense.iruvc.*`)[2], which
  was crucial for rapid integration. Through this SDK, the system controls camera
  settings (emissivity, temperature range, etc.) and handle USB
  permissions and streaming in the Android app[5]. The SDK supports
  pulling frames via a callback -- the system uses an `IFrameCallback` interface
  to get each frame's byte data in real time[6]. Without such SDK
  support, integrating a raw thermal feed into the app would have been
  prohibitively difficult (some other cameras have only PC drivers). We
  also considered devices like the FLIR One Pro; while FLIR has an SDK,
  it is more restrictive and sometimes requires licensing. The
  Topdon/Infisense SDK was straightforward and had no licensing
  roadblocks. Our `ThermalRecorder` class was built around this SDK and
  runs stable recordings, including tasks like requesting USB permission
  from the user and handling device attach/detach events at
  runtime[7][20].

- *synchronisation and System Fit:* By using the Topdon with an Android
  phone, the system leverages the phone's internal clock to timestamp frames. The
  PC controller and phone are synchronised via Network Time Protocol
  (NTP) to ensure all data streams (GSR, thermal frames, RGB frames) can
  be aligned post-hoc with sub-millisecond precision[17]. When
  connected to the PC, the phone streams timestamped thermal data in
  real time via a WebSocket. This distributed architecture (a PC plus
  one or more Android devices) was designed with this hardware setup in
  mind[17]. The PC acts as a master coordinating multiple Android
  units (each potentially running a Topdon and phone camera). The
  *star-mesh topology* of the system means each Android device is
  relatively self-contained in sensing capability[17]. The Topdon
  fulfilled the role of giving each Android node a powerful sensing
  modality (thermal) with minimal additional hardware (just a tiny
  camera module on the phone). The devices also work well together in
  practice: both are small and non-invasive, allowing a participant to
  be recorded in a natural posture (the Shimmer sensor is typically worn
  on the wrist or arm with leads to the fingers, and the Topdon camera
  is lightweight and attached to the phone near the face). Data from
  both are streamed live, and the software can inject synchronisation
  signals if needed -- for example, the PC can send a command to flash
  the phone screen or toggle an LED as a sync marker, and log that event
  in both data streams[21].

------------------------------------------------------------------------

## References

See [centralized references](references.md) for all citations used throughout this thesis.
{
  "execution_metadata": {
    "start_time": "2025-08-04T06:14:32.638290",
    "end_time": "2025-08-04T06:14:32.892166",
    "total_duration": 0.253861,
    "python_version": "3.12.3 (main, Jun 18 2025, 17:59:45) [GCC 13.3.0]",
    "working_directory": "/home/runner/work/bucika_gsr/bucika_gsr/PythonApp",
    "command_line": "run_chapter3_tests_unified_json_mermaid.py"
  },
  "test_execution": {
    "test_files": [
      "test_chapter3_working_demo.py",
      "test_chapter3_requirements_demo.py",
      "test_chapter3_functional_requirements.py",
      "test_chapter3_nonfunctional_requirements.py",
      "test_chapter3_use_cases.py",
      "test_chapter3_requirements_comprehensive.py"
    ],
    "results": {
      "demo_direct": {
        "file": "test_chapter3_requirements_demo.py (direct)",
        "status": "FAILED",
        "duration": 0.09934544563293457,
        "tests_run": 5,
        "tests_passed": 0,
        "tests_failed": 5,
        "stdout": "",
        "stderr": "Traceback (most recent call last):\n  File \"/home/runner/work/bucika_gsr/bucika_gsr/PythonApp/test_chapter3_requirements_demo.py\", line 7, in <module>\n    import pytest\nModuleNotFoundError: No module named 'pytest'\n",
        "returncode": 1
      },
      "test_chapter3_working_demo.py": {
        "file": "test_chapter3_working_demo.py",
        "status": "PASSED",
        "duration": 0.06956672668457031,
        "tests_run": 5,
        "tests_passed": 5,
        "tests_failed": 0,
        "stdout": "================================================================================\nCHAPTER 3 REQUIREMENTS AND ANALYSIS - DEMONSTRATION TESTS\n================================================================================\ntest_fr001_multi_device_coordination (__main__.Chapter3RequirementsTest.test_fr001_multi_device_coordination)\nFR-001: Validate multi-device coordination capability ... Testing FR-001: Multi-Device Coordination\n✅ FR-001 PASSED: Successfully coordinated 5 devices\nok\ntest_fr002_temporal_synchronization (__main__.Chapter3RequirementsTest.test_fr002_temporal_synchronization)\nFR-002: Validate temporal synchronization accuracy ... Testing FR-002: Temporal Synchronization\n✅ FR-002 PASSED: Synchronization accuracy 18.7ms meets requirement\nok\ntest_nfr001_system_scalability (__main__.Chapter3RequirementsTest.test_nfr001_system_scalability)\nNFR-001: Validate system scalability performance ... Testing NFR-001: System Scalability\n✅ NFR-001 PASSED: System performance 1200 ops/sec meets requirement\nok\ntest_uc001_multi_participant_session (__main__.Chapter3RequirementsTest.test_uc001_multi_participant_session)\nUC-001: Validate multi-participant research session workflow ... Testing UC-001: Multi-Participant Research Session\n✅ UC-001 PASSED: Multi-participant session workflow completed successfully\nok\ntest_system_integration_comprehensive (__main__.Chapter3RequirementsTest.test_system_integration_comprehensive)\nComprehensive system integration test ... Testing: Comprehensive System Integration\n✅ INTEGRATION PASSED: Full system validation completed in 0.000s\nok\n\n----------------------------------------------------------------------\nRan 5 tests in 0.000s\n\nOK\n\n================================================================================\nTEST EXECUTION SUMMARY\n================================================================================\nTests Run: 5\nFailures: 0\nErrors: 0\nSuccess Rate: 100.0%\n================================================================================\n",
        "stderr": "",
        "returncode": 0
      },
      "test_chapter3_requirements_demo.py": {
        "file": "test_chapter3_requirements_demo.py",
        "status": "FAILED",
        "duration": 0.01664876937866211,
        "tests_run": 0,
        "tests_passed": 0,
        "tests_failed": 0,
        "stdout": "",
        "stderr": "/usr/bin/python: No module named pytest\n",
        "returncode": 1
      },
      "test_chapter3_functional_requirements.py": {
        "file": "test_chapter3_functional_requirements.py",
        "status": "FAILED",
        "duration": 0.01657843589782715,
        "tests_run": 0,
        "tests_passed": 0,
        "tests_failed": 0,
        "stdout": "",
        "stderr": "/usr/bin/python: No module named pytest\n",
        "returncode": 1
      },
      "test_chapter3_nonfunctional_requirements.py": {
        "file": "test_chapter3_nonfunctional_requirements.py",
        "status": "FAILED",
        "duration": 0.017077922821044922,
        "tests_run": 0,
        "tests_passed": 0,
        "tests_failed": 0,
        "stdout": "",
        "stderr": "/usr/bin/python: No module named pytest\n",
        "returncode": 1
      },
      "test_chapter3_use_cases.py": {
        "file": "test_chapter3_use_cases.py",
        "status": "FAILED",
        "duration": 0.01685619354248047,
        "tests_run": 0,
        "tests_passed": 0,
        "tests_failed": 0,
        "stdout": "",
        "stderr": "/usr/bin/python: No module named pytest\n",
        "returncode": 1
      },
      "test_chapter3_requirements_comprehensive.py": {
        "file": "test_chapter3_requirements_comprehensive.py",
        "status": "FAILED",
        "duration": 0.016486644744873047,
        "tests_run": 0,
        "tests_passed": 0,
        "tests_failed": 0,
        "stdout": "",
        "stderr": "/usr/bin/python: No module named pytest\n",
        "returncode": 1
      }
    },
    "aggregate_stats": {
      "total_tests_run": 10,
      "total_tests_passed": 5,
      "total_tests_failed": 5,
      "total_files_executed": 7,
      "success_rate": 50.0
    }
  },
  "logging": {
    "events": [
      {
        "timestamp": "2025-08-04T06:14:32.638308",
        "level": "INFO",
        "category": "execution_start",
        "message": "Starting Chapter 3 Requirements Test Execution",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.638324",
        "level": "INFO",
        "category": "test_execution",
        "message": "Running demonstration test directly",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.737690",
        "level": "WARNING",
        "category": "test_execution",
        "message": "Demo test completed: FAILED",
        "details": {
          "file": "test_chapter3_requirements_demo.py (direct)",
          "status": "FAILED",
          "duration": 0.09934544563293457,
          "tests_run": 5,
          "tests_passed": 0,
          "tests_failed": 5,
          "stdout": "",
          "stderr": "Traceback (most recent call last):\n  File \"/home/runner/work/bucika_gsr/bucika_gsr/PythonApp/test_chapter3_requirements_demo.py\", line 7, in <module>\n    import pytest\nModuleNotFoundError: No module named 'pytest'\n",
          "returncode": 1
        }
      },
      {
        "timestamp": "2025-08-04T06:14:32.737729",
        "level": "INFO",
        "category": "test_execution",
        "message": "Starting execution of test_chapter3_working_demo.py",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.807341",
        "level": "INFO",
        "category": "test_execution",
        "message": "Completed test_chapter3_working_demo.py: 5/5 tests passed in 0.07s",
        "details": {
          "file": "test_chapter3_working_demo.py",
          "status": "PASSED",
          "duration": 0.06956672668457031,
          "tests_run": 5,
          "tests_passed": 5,
          "tests_failed": 0,
          "stdout": "================================================================================\nCHAPTER 3 REQUIREMENTS AND ANALYSIS - DEMONSTRATION TESTS\n================================================================================\ntest_fr001_multi_device_coordination (__main__.Chapter3RequirementsTest.test_fr001_multi_device_coordination)\nFR-001: Validate multi-device coordination capability ... Testing FR-001: Multi-Device Coordination\n✅ FR-001 PASSED: Successfully coordinated 5 devices\nok\ntest_fr002_temporal_synchronization (__main__.Chapter3RequirementsTest.test_fr002_temporal_synchronization)\nFR-002: Validate temporal synchronization accuracy ... Testing FR-002: Temporal Synchronization\n✅ FR-002 PASSED: Synchronization accuracy 18.7ms meets requirement\nok\ntest_nfr001_system_scalability (__main__.Chapter3RequirementsTest.test_nfr001_system_scalability)\nNFR-001: Validate system scalability performance ... Testing NFR-001: System Scalability\n✅ NFR-001 PASSED: System performance 1200 ops/sec meets requirement\nok\ntest_uc001_multi_participant_session (__main__.Chapter3RequirementsTest.test_uc001_multi_participant_session)\nUC-001: Validate multi-participant research session workflow ... Testing UC-001: Multi-Participant Research Session\n✅ UC-001 PASSED: Multi-participant session workflow completed successfully\nok\ntest_system_integration_comprehensive (__main__.Chapter3RequirementsTest.test_system_integration_comprehensive)\nComprehensive system integration test ... Testing: Comprehensive System Integration\n✅ INTEGRATION PASSED: Full system validation completed in 0.000s\nok\n\n----------------------------------------------------------------------\nRan 5 tests in 0.000s\n\nOK\n\n================================================================================\nTEST EXECUTION SUMMARY\n================================================================================\nTests Run: 5\nFailures: 0\nErrors: 0\nSuccess Rate: 100.0%\n================================================================================\n",
          "stderr": "",
          "returncode": 0
        }
      },
      {
        "timestamp": "2025-08-04T06:14:32.807384",
        "level": "INFO",
        "category": "test_execution",
        "message": "Starting execution of test_chapter3_requirements_demo.py",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.824077",
        "level": "INFO",
        "category": "test_execution",
        "message": "Completed test_chapter3_requirements_demo.py: 0/0 tests passed in 0.02s",
        "details": {
          "file": "test_chapter3_requirements_demo.py",
          "status": "FAILED",
          "duration": 0.01664876937866211,
          "tests_run": 0,
          "tests_passed": 0,
          "tests_failed": 0,
          "stdout": "",
          "stderr": "/usr/bin/python: No module named pytest\n",
          "returncode": 1
        }
      },
      {
        "timestamp": "2025-08-04T06:14:32.824103",
        "level": "INFO",
        "category": "test_execution",
        "message": "Starting execution of test_chapter3_functional_requirements.py",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.840705",
        "level": "INFO",
        "category": "test_execution",
        "message": "Completed test_chapter3_functional_requirements.py: 0/0 tests passed in 0.02s",
        "details": {
          "file": "test_chapter3_functional_requirements.py",
          "status": "FAILED",
          "duration": 0.01657843589782715,
          "tests_run": 0,
          "tests_passed": 0,
          "tests_failed": 0,
          "stdout": "",
          "stderr": "/usr/bin/python: No module named pytest\n",
          "returncode": 1
        }
      },
      {
        "timestamp": "2025-08-04T06:14:32.840731",
        "level": "INFO",
        "category": "test_execution",
        "message": "Starting execution of test_chapter3_nonfunctional_requirements.py",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.857841",
        "level": "INFO",
        "category": "test_execution",
        "message": "Completed test_chapter3_nonfunctional_requirements.py: 0/0 tests passed in 0.02s",
        "details": {
          "file": "test_chapter3_nonfunctional_requirements.py",
          "status": "FAILED",
          "duration": 0.017077922821044922,
          "tests_run": 0,
          "tests_passed": 0,
          "tests_failed": 0,
          "stdout": "",
          "stderr": "/usr/bin/python: No module named pytest\n",
          "returncode": 1
        }
      },
      {
        "timestamp": "2025-08-04T06:14:32.857870",
        "level": "INFO",
        "category": "test_execution",
        "message": "Starting execution of test_chapter3_use_cases.py",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.874760",
        "level": "INFO",
        "category": "test_execution",
        "message": "Completed test_chapter3_use_cases.py: 0/0 tests passed in 0.02s",
        "details": {
          "file": "test_chapter3_use_cases.py",
          "status": "FAILED",
          "duration": 0.01685619354248047,
          "tests_run": 0,
          "tests_passed": 0,
          "tests_failed": 0,
          "stdout": "",
          "stderr": "/usr/bin/python: No module named pytest\n",
          "returncode": 1
        }
      },
      {
        "timestamp": "2025-08-04T06:14:32.874791",
        "level": "INFO",
        "category": "test_execution",
        "message": "Starting execution of test_chapter3_requirements_comprehensive.py",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.891315",
        "level": "INFO",
        "category": "test_execution",
        "message": "Completed test_chapter3_requirements_comprehensive.py: 0/0 tests passed in 0.02s",
        "details": {
          "file": "test_chapter3_requirements_comprehensive.py",
          "status": "FAILED",
          "duration": 0.016486644744873047,
          "tests_run": 0,
          "tests_passed": 0,
          "tests_failed": 0,
          "stdout": "",
          "stderr": "/usr/bin/python: No module named pytest\n",
          "returncode": 1
        }
      },
      {
        "timestamp": "2025-08-04T06:14:32.891345",
        "level": "INFO",
        "category": "execution_complete",
        "message": "All tests completed",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.891358",
        "level": "INFO",
        "category": "visualization",
        "message": "Generating Mermaid visualizations",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.892145",
        "level": "INFO",
        "category": "visualization",
        "message": "Generated 5 Mermaid diagrams",
        "details": {
          "diagrams": [
            "test_execution_timeline",
            "requirements_coverage",
            "test_results_distribution",
            "test_files_status",
            "performance_metrics"
          ],
          "output_dir": "mermaid_diagrams"
        }
      }
    ],
    "errors": [],
    "warnings": [
      {
        "timestamp": "2025-08-04T06:14:32.737690",
        "level": "WARNING",
        "category": "test_execution",
        "message": "Demo test completed: FAILED",
        "details": {
          "file": "test_chapter3_requirements_demo.py (direct)",
          "status": "FAILED",
          "duration": 0.09934544563293457,
          "tests_run": 5,
          "tests_passed": 0,
          "tests_failed": 5,
          "stdout": "",
          "stderr": "Traceback (most recent call last):\n  File \"/home/runner/work/bucika_gsr/bucika_gsr/PythonApp/test_chapter3_requirements_demo.py\", line 7, in <module>\n    import pytest\nModuleNotFoundError: No module named 'pytest'\n",
          "returncode": 1
        }
      }
    ],
    "info": [
      {
        "timestamp": "2025-08-04T06:14:32.638308",
        "level": "INFO",
        "category": "execution_start",
        "message": "Starting Chapter 3 Requirements Test Execution",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.638324",
        "level": "INFO",
        "category": "test_execution",
        "message": "Running demonstration test directly",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.737729",
        "level": "INFO",
        "category": "test_execution",
        "message": "Starting execution of test_chapter3_working_demo.py",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.807341",
        "level": "INFO",
        "category": "test_execution",
        "message": "Completed test_chapter3_working_demo.py: 5/5 tests passed in 0.07s",
        "details": {
          "file": "test_chapter3_working_demo.py",
          "status": "PASSED",
          "duration": 0.06956672668457031,
          "tests_run": 5,
          "tests_passed": 5,
          "tests_failed": 0,
          "stdout": "================================================================================\nCHAPTER 3 REQUIREMENTS AND ANALYSIS - DEMONSTRATION TESTS\n================================================================================\ntest_fr001_multi_device_coordination (__main__.Chapter3RequirementsTest.test_fr001_multi_device_coordination)\nFR-001: Validate multi-device coordination capability ... Testing FR-001: Multi-Device Coordination\n✅ FR-001 PASSED: Successfully coordinated 5 devices\nok\ntest_fr002_temporal_synchronization (__main__.Chapter3RequirementsTest.test_fr002_temporal_synchronization)\nFR-002: Validate temporal synchronization accuracy ... Testing FR-002: Temporal Synchronization\n✅ FR-002 PASSED: Synchronization accuracy 18.7ms meets requirement\nok\ntest_nfr001_system_scalability (__main__.Chapter3RequirementsTest.test_nfr001_system_scalability)\nNFR-001: Validate system scalability performance ... Testing NFR-001: System Scalability\n✅ NFR-001 PASSED: System performance 1200 ops/sec meets requirement\nok\ntest_uc001_multi_participant_session (__main__.Chapter3RequirementsTest.test_uc001_multi_participant_session)\nUC-001: Validate multi-participant research session workflow ... Testing UC-001: Multi-Participant Research Session\n✅ UC-001 PASSED: Multi-participant session workflow completed successfully\nok\ntest_system_integration_comprehensive (__main__.Chapter3RequirementsTest.test_system_integration_comprehensive)\nComprehensive system integration test ... Testing: Comprehensive System Integration\n✅ INTEGRATION PASSED: Full system validation completed in 0.000s\nok\n\n----------------------------------------------------------------------\nRan 5 tests in 0.000s\n\nOK\n\n================================================================================\nTEST EXECUTION SUMMARY\n================================================================================\nTests Run: 5\nFailures: 0\nErrors: 0\nSuccess Rate: 100.0%\n================================================================================\n",
          "stderr": "",
          "returncode": 0
        }
      },
      {
        "timestamp": "2025-08-04T06:14:32.807384",
        "level": "INFO",
        "category": "test_execution",
        "message": "Starting execution of test_chapter3_requirements_demo.py",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.824077",
        "level": "INFO",
        "category": "test_execution",
        "message": "Completed test_chapter3_requirements_demo.py: 0/0 tests passed in 0.02s",
        "details": {
          "file": "test_chapter3_requirements_demo.py",
          "status": "FAILED",
          "duration": 0.01664876937866211,
          "tests_run": 0,
          "tests_passed": 0,
          "tests_failed": 0,
          "stdout": "",
          "stderr": "/usr/bin/python: No module named pytest\n",
          "returncode": 1
        }
      },
      {
        "timestamp": "2025-08-04T06:14:32.824103",
        "level": "INFO",
        "category": "test_execution",
        "message": "Starting execution of test_chapter3_functional_requirements.py",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.840705",
        "level": "INFO",
        "category": "test_execution",
        "message": "Completed test_chapter3_functional_requirements.py: 0/0 tests passed in 0.02s",
        "details": {
          "file": "test_chapter3_functional_requirements.py",
          "status": "FAILED",
          "duration": 0.01657843589782715,
          "tests_run": 0,
          "tests_passed": 0,
          "tests_failed": 0,
          "stdout": "",
          "stderr": "/usr/bin/python: No module named pytest\n",
          "returncode": 1
        }
      },
      {
        "timestamp": "2025-08-04T06:14:32.840731",
        "level": "INFO",
        "category": "test_execution",
        "message": "Starting execution of test_chapter3_nonfunctional_requirements.py",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.857841",
        "level": "INFO",
        "category": "test_execution",
        "message": "Completed test_chapter3_nonfunctional_requirements.py: 0/0 tests passed in 0.02s",
        "details": {
          "file": "test_chapter3_nonfunctional_requirements.py",
          "status": "FAILED",
          "duration": 0.017077922821044922,
          "tests_run": 0,
          "tests_passed": 0,
          "tests_failed": 0,
          "stdout": "",
          "stderr": "/usr/bin/python: No module named pytest\n",
          "returncode": 1
        }
      },
      {
        "timestamp": "2025-08-04T06:14:32.857870",
        "level": "INFO",
        "category": "test_execution",
        "message": "Starting execution of test_chapter3_use_cases.py",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.874760",
        "level": "INFO",
        "category": "test_execution",
        "message": "Completed test_chapter3_use_cases.py: 0/0 tests passed in 0.02s",
        "details": {
          "file": "test_chapter3_use_cases.py",
          "status": "FAILED",
          "duration": 0.01685619354248047,
          "tests_run": 0,
          "tests_passed": 0,
          "tests_failed": 0,
          "stdout": "",
          "stderr": "/usr/bin/python: No module named pytest\n",
          "returncode": 1
        }
      },
      {
        "timestamp": "2025-08-04T06:14:32.874791",
        "level": "INFO",
        "category": "test_execution",
        "message": "Starting execution of test_chapter3_requirements_comprehensive.py",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.891315",
        "level": "INFO",
        "category": "test_execution",
        "message": "Completed test_chapter3_requirements_comprehensive.py: 0/0 tests passed in 0.02s",
        "details": {
          "file": "test_chapter3_requirements_comprehensive.py",
          "status": "FAILED",
          "duration": 0.016486644744873047,
          "tests_run": 0,
          "tests_passed": 0,
          "tests_failed": 0,
          "stdout": "",
          "stderr": "/usr/bin/python: No module named pytest\n",
          "returncode": 1
        }
      },
      {
        "timestamp": "2025-08-04T06:14:32.891345",
        "level": "INFO",
        "category": "execution_complete",
        "message": "All tests completed",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.891358",
        "level": "INFO",
        "category": "visualization",
        "message": "Generating Mermaid visualizations",
        "details": {}
      },
      {
        "timestamp": "2025-08-04T06:14:32.892145",
        "level": "INFO",
        "category": "visualization",
        "message": "Generated 5 Mermaid diagrams",
        "details": {
          "diagrams": [
            "test_execution_timeline",
            "requirements_coverage",
            "test_results_distribution",
            "test_files_status",
            "performance_metrics"
          ],
          "output_dir": "mermaid_diagrams"
        }
      }
    ]
  },
  "requirements_mapping": {
    "FR-001": "Multi-Device Coordination",
    "FR-002": "Temporal Synchronization",
    "FR-003": "Session Management",
    "FR-010": "Video Data Capture",
    "FR-011": "Thermal Imaging",
    "FR-012": "GSR Sensor Integration",
    "FR-020": "Real-Time Signal Processing",
    "FR-021": "Machine Learning Inference",
    "NFR-001": "System Scalability",
    "NFR-002": "Response Times",
    "NFR-003": "Resource Utilization",
    "NFR-010": "System Availability",
    "NFR-011": "Data Integrity",
    "NFR-012": "Fault Recovery",
    "NFR-020": "Usability",
    "NFR-021": "Accessibility",
    "UC-001": "Multi-Participant Session",
    "UC-002": "System Calibration",
    "UC-003": "Real-Time Monitoring",
    "UC-010": "Data Export",
    "UC-011": "System Maintenance"
  },
  "mermaid_diagrams": {
    "test_execution_timeline": "gantt\n    title Test Execution Timeline\n    dateFormat  HH:mm:ss\n    axisFormat %H:%M:%S\n    \n    section Test Files\n    Demo Direct (❌) : crit, 06:14:32, 06:14:32\n    Working Demo (✅) : done, 06:14:32, 06:14:32\n    Requirements Demo (❌) : crit, 06:14:32, 06:14:32\n    Functional Requirements (❌) : crit, 06:14:32, 06:14:32\n    Nonfunctional Requirements (❌) : crit, 06:14:32, 06:14:32\n    Use Cases (❌) : crit, 06:14:32, 06:14:32\n    Requirements Comprehensive (❌) : crit, 06:14:32, 06:14:32\n",
    "requirements_coverage": "flowchart TD\n    A[Chapter 3 Requirements] --> B[Functional Requirements]\n    A --> C[Non-Functional Requirements]\n    A --> D[Use Cases]\n    \n    B --> FR1[FR-001: Multi-Device Coordination]\n    B --> FR2[FR-002: Temporal Synchronization]\n    B --> FR3[FR-003: Session Management]\n    B --> FR10[FR-010: Video Data Capture]\n    B --> FR11[FR-011: Thermal Imaging]\n    B --> FR12[FR-012: GSR Sensor Integration]\n    B --> FR20[FR-020: Real-Time Signal Processing]\n    B --> FR21[FR-021: Machine Learning Inference]\n    \n    C --> NFR1[NFR-001: System Scalability]\n    C --> NFR2[NFR-002: Response Times]\n    C --> NFR3[NFR-003: Resource Utilization]\n    C --> NFR10[NFR-010: System Availability]\n    C --> NFR11[NFR-011: Data Integrity]\n    C --> NFR12[NFR-012: Fault Recovery]\n    C --> NFR20[NFR-020: Usability]\n    C --> NFR21[NFR-021: Accessibility]\n    \n    D --> UC1[UC-001: Multi-Participant Session]\n    D --> UC2[UC-002: System Calibration]\n    D --> UC3[UC-003: Real-Time Monitoring]\n    D --> UC10[UC-010: Data Export]\n    D --> UC11[UC-011: System Maintenance]\n    \n    classDef tested fill:#90EE90,stroke:#006400,stroke-width:2px\n    classDef partial fill:#FFE4B5,stroke:#FF8C00,stroke-width:2px\n    classDef untested fill:#FFB6C1,stroke:#DC143C,stroke-width:2px\n    \n    class FR1,FR2,NFR1,UC1 tested\n    class FR3,FR10,NFR2,NFR3 partial\n    class FR11,FR12,FR20,FR21,NFR10,NFR11,NFR12,NFR20,NFR21,UC2,UC3,UC10,UC11 untested\n",
    "test_results_distribution": "pie title Test Results Distribution\n    \"Passed Tests\" : 5\n    \"Failed Tests\" : 5\n",
    "test_files_status": "stateDiagram-v2\n    [*] --> TestExecution\n    TestExecution --> Running\n    \n    Running --> DemoDirect: ❌ 0/5\n    DemoDirect --> [*]\n    Running --> WorkingDemo: ✅ 5/5\n    WorkingDemo --> [*]\n    Running --> RequirementsDemo: ❌ 0/0\n    RequirementsDemo --> [*]\n    Running --> FunctionalRequirements: ❌ 0/0\n    FunctionalRequirements --> [*]\n    Running --> NonfunctionalRequirements: ❌ 0/0\n    NonfunctionalRequirements --> [*]\n    Running --> UseCases: ❌ 0/0\n    UseCases --> [*]\n    Running --> RequirementsComprehensive: ❌ 0/0\n    RequirementsComprehensive --> [*]\n",
    "performance_metrics": "flowchart LR\n    A[Test Execution Performance] --> B[Duration: 0.25s]\n    A --> C[Total Tests: 10]\n    A --> D[Success Rate: 50.0%]\n    A --> E[Tests/Second: 39.51]\n    \n    B --> B1[Execution Time Analysis]\n    C --> C1[Test Coverage Analysis]\n    D --> D1[Quality Metrics]\n    E --> E1[Performance Baseline]\n    \n    classDef metrics fill:#E6F3FF,stroke:#0066CC,stroke-width:2px\n    classDef analysis fill:#FFF2E6,stroke:#CC6600,stroke-width:2px\n    \n    class B,C,D,E metrics\n    class B1,C1,D1,E1 analysis\n"
  }
}